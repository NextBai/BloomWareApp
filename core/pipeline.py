import asyncio
import logging
from dataclasses import dataclass
from typing import Any, Awaitable, Callable, Optional, Dict, Tuple, List

from core.emotion_care_manager import EmotionCareManager

logger = logging.getLogger(__name__)


@dataclass
class PipelineResult:
    text: str
    is_fallback: bool = False
    reason: Optional[str] = None  # e.g., "timeout", "error", "no_intent"
    meta: Optional[Dict[str, Any]] = None


class ChatPipeline:
    """
    éé˜»å¡èŠå¤©è™•ç†ç®¡ç·šï¼Œé€éä¾è³´æ³¨å…¥ä»¥ä¾¿æ¸¬è©¦èˆ‡æ›¿æ›å¯¦ä½œã€‚

    ä¾è³´ï¼ˆçš†ç‚ºå¯ await çš„ callablesï¼‰ï¼š
    - intent_detector(message) -> tuple[bool, intent_data]
    - feature_processor(intent_data, user_id, original_message, chat_id) -> str
    - ai_generator(messages:list[dict], client_id:str, model:str|None, request_id:str|None, chat_id:str|None) -> str
    
    å·²ç§»é™¤æœªä½¿ç”¨çš„ä¾è³´ï¼š
    - memory_manager: çŸ­æœŸè¨˜æ†¶ç®¡ç†ï¼ˆæœªä½¿ç”¨ï¼Œå·²æ”¹ç”¨ memory_systemï¼‰
    - summary_gate: æ‘˜è¦æ±ºç­–ï¼ˆéåº¦ç°¡åŒ–ï¼Œå·²ç§»é™¤ï¼‰
    """

    def __init__(
        self,
        intent_detector: Callable[[str], Awaitable[Tuple[bool, dict]]],
        feature_processor: Callable[[dict, str, str, Optional[str]], Awaitable[Any]],
        ai_generator: Callable[..., Awaitable[str]],
        model: str = "gpt-5-nano",
        detect_timeout: float = 5.0,    # 2025 æœ€ä½³å¯¦è¸ï¼šStructured Outputs é€šå¸¸ 2-3ç§’
        feature_timeout: float = 10.0,  # MCP å·¥å…·å·²æœ‰å…§éƒ¨è¶…æ™‚ï¼ˆ30ç§’ï¼‰
        ai_timeout: float = 12.0,       # é…åˆ Streamingï¼ˆé¦–æ¬¡å›æ‡‰ 0.5-1ç§’ï¼‰
    ) -> None:
        self._intent_detector = intent_detector
        self._feature_processor = feature_processor
        self._ai_generator = ai_generator
        self._detect_timeout = detect_timeout
        self._feature_timeout = feature_timeout
        self._ai_timeout = ai_timeout
        self._model = model

    def _is_chinese_message(self, text: str) -> bool:
        """
        ç°¡åŒ–èªè¨€åˆ¤æ–·ï¼šæª¢æ¸¬è¨Šæ¯æ˜¯å¦ç‚ºä¸­æ–‡

        Args:
            text: ç”¨æˆ¶è¨Šæ¯

        Returns:
            True å¦‚æœè¨Šæ¯ä¸»è¦æ˜¯ä¸­æ–‡ï¼ŒFalse å¦‚æœæ˜¯å…¶ä»–èªè¨€
        """
        if not text:
            return True  # é è¨­ç‚ºä¸­æ–‡

        # è¨ˆç®—ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        total_chars = len(text.replace(' ', '').replace('\n', ''))

        if total_chars == 0:
            return True

        # å¦‚æœä¸­æ–‡å­—ç¬¦è¶…é 30%ï¼Œè¦–ç‚ºä¸­æ–‡è¨Šæ¯
        return chinese_chars > total_chars * 0.3

    async def _translate_tool_data(self, tool_data: Dict[str, Any], user_message: str) -> Dict[str, Any]:
        """
        ç°¡åŒ–ç‰ˆå·¥å…·å¡ç‰‡ç¿»è­¯ï¼šè®“ GPT è‡ªå‹•åˆ¤æ–·ç›®æ¨™èªè¨€

        Args:
            tool_data: å·¥å…·è³‡æ–™å­—å…¸
            user_message: ç”¨æˆ¶åŸå§‹è¨Šæ¯ï¼ˆç”¨æ–¼æ¨æ–·ç›®æ¨™èªè¨€ï¼‰

        Returns:
            ç¿»è­¯å¾Œçš„å·¥å…·è³‡æ–™
        """
        if not tool_data:
            return tool_data

        try:
            import copy
            translated_data = copy.deepcopy(tool_data)

            # éœ€è¦ç¿»è­¯çš„æ¬„ä½ï¼ˆå¤©æ°£ã€æ–°èç­‰å·¥å…·çš„é¡¯ç¤ºæ¬„ä½ï¼‰
            translatable_keys = {
                "description", "main", "name", "title", "summary",
                "content", "message", "text", "label", "status"
            }

            # æ”¶é›†éœ€è¦ç¿»è­¯çš„æ–‡å­—
            texts_to_translate = []
            text_paths = []

            def collect_texts(obj, path="", parent_key=""):
                """éè¿´æ”¶é›†éœ€è¦ç¿»è­¯çš„æ–‡å­—"""
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        new_path = f"{path}.{key}" if path else key
                        # è·³éæŠ€è¡“æ¬„ä½
                        if key in ("id", "url", "link", "lat", "lon", "timestamp", "code", "icon"):
                            continue
                        collect_texts(value, new_path, key)
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        collect_texts(item, f"{path}[{i}]", parent_key)
                elif isinstance(obj, str) and len(obj) > 1:
                    # éœ€è¦ç¿»è­¯çš„æ¢ä»¶
                    should_translate = (
                        parent_key.lower() in translatable_keys or
                        any('\u4e00' <= c <= '\u9fff' for c in obj)  # åŒ…å«ä¸­æ–‡
                    )
                    if should_translate:
                        texts_to_translate.append(obj)
                        text_paths.append(path)

            collect_texts(translated_data)

            if not texts_to_translate:
                return tool_data

            # æ‰¹é‡ç¿»è­¯ï¼ˆè®“ GPT è‡ªå‹•åˆ¤æ–·ç›®æ¨™èªè¨€ï¼‰
            import services.ai_service as ai_service

            combined_text = "\n---\n".join(texts_to_translate)
            messages = [
                {
                    "role": "system",
                    "content": f"å°‡ä»¥ä¸‹å…§å®¹ç¿»è­¯æˆèˆ‡ç”¨æˆ¶è¨Šæ¯ã€Œ{user_message}ã€ç›¸åŒçš„èªè¨€ã€‚ä¿æŒæ ¼å¼å’Œè¡¨æƒ…ç¬¦è™Ÿã€‚æ¯æ®µç”¨ '---' åˆ†éš”ï¼Œè¼¸å‡ºä¹Ÿç”¨ '---' åˆ†éš”ã€‚åªè¼¸å‡ºç¿»è­¯çµæœï¼Œä¸è¦åŠ è§£é‡‹ã€‚"
                },
                {"role": "user", "content": combined_text}
            ]

            translated = await ai_service.generate_response_async(
                messages=messages,
                model="gpt-5-nano",
                reasoning_effort="minimal",
                max_tokens=800,
            )

            if translated:
                translated_parts = translated.strip().split("---")
                translated_parts = [p.strip() for p in translated_parts if p.strip()]

                # å›å¡«ç¿»è­¯çµæœ
                def set_value(obj, path, value):
                    parts = path.replace("]", "").replace("[", ".").split(".")
                    for part in parts[:-1]:
                        if part.isdigit():
                            obj = obj[int(part)]
                        else:
                            obj = obj[part]
                    last = parts[-1]
                    if last.isdigit():
                        obj[int(last)] = value
                    else:
                        obj[last] = value

                for i, path in enumerate(text_paths):
                    if i < len(translated_parts):
                        try:
                            set_value(translated_data, path, translated_parts[i])
                        except Exception:
                            pass

            logger.info(f"ğŸŒ å·¥å…·å¡ç‰‡å·²ç¿»è­¯: {len(texts_to_translate)} å€‹æ¬„ä½")
            return translated_data

        except Exception as e:
            logger.warning(f"âš ï¸ å·¥å…·å¡ç‰‡ç¿»è­¯å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ•¸æ“š: {e}")
            return tool_data

    async def _with_timeout(self, coro: Awaitable[Any], timeout: float, reason: str) -> Any:
        try:
            return await asyncio.wait_for(coro, timeout=timeout)
        except asyncio.TimeoutError:
            return PipelineResult(
                text="æŠ±æ­‰ï¼Œæˆ‘é€™é‚Šæœ‰é»å¿™ç¢Œï¼Œç¨å¾Œå†è©¦å¯ä»¥å—ï¼Ÿ",
                is_fallback=True,
                reason=reason,
                meta={"timeout": timeout},
            )
        except Exception as e:
            return PipelineResult(
                text=f"æŠ±æ­‰ï¼Œè™•ç†æ™‚ç¢°åˆ°ç‹€æ³ï¼š{e}",
                is_fallback=True,
                reason=reason,
                meta={"error": str(e)},
            )

    async def process(
        self,
        user_message: str,
        user_id: Optional[str] = None,
        chat_id: Optional[str] = None,
        request_id: Optional[str] = None,
        audio_emotion: Optional[Dict[str, Any]] = None,
        language: Optional[str] = None,
    ) -> PipelineResult:
        if not user_message or not user_message.strip():
            return PipelineResult(text="æˆ‘æ²’æœ‰æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚", is_fallback=True, reason="empty")

        # language åƒæ•¸ä¿ç•™ä»¥å‘å¾Œå…¼å®¹ï¼Œä½†ä¸ä½¿ç”¨ï¼ˆGPT è‡ªå‹•åˆ¤æ–·èªè¨€ï¼‰

        # 0) å…ˆé€²è¡Œæ„åœ–åµæ¸¬ä»¥æå–æƒ…ç·’ï¼ˆéœ€è¦åœ¨é—œæ‡·æ¨¡å¼æª¢æŸ¥å‰åŸ·è¡Œï¼‰
        detect_res = await self._with_timeout(
            self._intent_detector(user_message), self._detect_timeout, reason="detect"
        )
        if isinstance(detect_res, PipelineResult):
            return detect_res
        has_feature, intent_data = detect_res

        # æå–æƒ…ç·’ï¼ˆé›™è»Œåˆ¶ï¼šéŸ³é »æƒ…ç·’å„ªå…ˆï¼Œæ–‡å­—æƒ…ç·’è¼”åŠ©ï¼‰
        text_emotion = intent_data.get("emotion", "neutral") if intent_data else "neutral"
        
        # æƒ…ç·’èåˆé‚è¼¯
        if audio_emotion and audio_emotion.get("success"):
            audio_emotion_label = audio_emotion.get("emotion", "neutral")
            audio_confidence = audio_emotion.get("confidence", 0.0)
            
            # å„ªå…ˆä½¿ç”¨éŸ³é »æƒ…ç·’ï¼ˆç½®ä¿¡åº¦ >= 0.5ï¼‰
            if audio_confidence >= 0.5:
                emotion_value = audio_emotion_label
                logger.info(f"ğŸ­ ä½¿ç”¨éŸ³é »æƒ…ç·’: {emotion_value} (ç½®ä¿¡åº¦: {audio_confidence:.4f})")
                logger.info(f"ğŸ“ æ–‡å­—æƒ…ç·’: {text_emotion} (è¼”åŠ©)")
            else:
                emotion_value = text_emotion
                logger.info(f"ğŸ“ ä½¿ç”¨æ–‡å­—æƒ…ç·’: {emotion_value} (éŸ³é »ç½®ä¿¡åº¦éä½: {audio_confidence:.4f})")
        else:
            emotion_value = text_emotion
            logger.info(f"ğŸ“ ä½¿ç”¨æ–‡å­—æƒ…ç·’: {emotion_value} (ç„¡éŸ³é »æƒ…ç·’)")

        # 1) æª¢æŸ¥æ˜¯å¦åœ¨é—œæ‡·æ¨¡å¼
        if user_id and EmotionCareManager.is_in_care_mode(user_id, chat_id):
            # æª¢æŸ¥æ˜¯å¦è§£é™¤é—œæ‡·æ¨¡å¼ï¼ˆå‚³å…¥æƒ…ç·’è³‡è¨Šï¼‰
            if EmotionCareManager.check_release(user_id, user_message, chat_id, emotion=emotion_value):
                logger.info(f"âœ… ç”¨æˆ¶ {user_id} æƒ…ç·’æ¢å¾©ï¼Œè§£é™¤é—œæ‡·æ¨¡å¼ï¼Œç¹¼çºŒæ­£å¸¸æµç¨‹")
                # è§£é™¤å¾Œç¹¼çºŒæ­£å¸¸æµç¨‹
            else:
                logger.info(f"ğŸ’™ ç”¨æˆ¶ {user_id} åœ¨é—œæ‡·æ¨¡å¼ä¸­ï¼Œè·³éå·¥å…·èª¿ç”¨ï¼Œä½¿ç”¨é—œæ‡· AI")
                # ç›´æ¥ç”¨é—œæ‡·æ¨¡å¼ AI å›æ‡‰ï¼ˆä¸æª¢æ¸¬æ„åœ–ï¼Œä¸èª¿ç”¨å·¥å…·ï¼‰
                care_emotion = EmotionCareManager.get_care_emotion(user_id, chat_id)
                ai_res = await self._with_timeout(
                    self._ai_generator(
                        user_message,
                        user_id,
                        self._model,
                        request_id,
                        chat_id,
                        use_care_mode=True,
                        care_emotion=care_emotion,
                        emotion_label=care_emotion,
                    ),
                    self._ai_timeout,
                    reason="ai-care",
                )
                if isinstance(ai_res, PipelineResult):
                    return ai_res
                text = str(ai_res or "").strip()
                if not text:
                    return PipelineResult(text="æˆ‘åœ¨é€™è£¡é™ªä½ ï¼Œéš¨æ™‚å¯ä»¥èŠèŠã€‚", is_fallback=True, reason="ai-care-empty")
                return PipelineResult(text=text, is_fallback=False, meta={"care_mode": True, "emotion": care_emotion})

        # 2) æª¢æŸ¥æ˜¯å¦éœ€è¦é€²å…¥é—œæ‡·æ¨¡å¼
        if user_id and EmotionCareManager.check_and_enter_care_mode(user_id, emotion_value, chat_id):
            logger.warning(f"âš ï¸ åµæ¸¬åˆ°æ¥µç«¯æƒ…ç·’ [{emotion_value}]ï¼Œé€²å…¥é—œæ‡·æ¨¡å¼")
            # ç«‹å³ä½¿ç”¨é—œæ‡·æ¨¡å¼ AI å›æ‡‰
            ai_res = await self._with_timeout(
                self._ai_generator(
                    user_message,
                    user_id,
                    self._model,
                    request_id,
                    chat_id,
                    use_care_mode=True,
                    care_emotion=emotion_value,
                    emotion_label=emotion_value,
                ),
                self._ai_timeout,
                reason="ai-care",
            )
            if isinstance(ai_res, PipelineResult):
                return ai_res
            text = str(ai_res or "").strip()
            if not text:
                text = "æˆ‘è½åˆ°äº†ï¼Œæˆ‘åœ¨é€™è£¡é™ªä½ ã€‚"

            # ç¬¬ä¸€æ¬¡é€²å…¥é—œæ‡·æ¨¡å¼æ™‚ï¼Œé™„åŠ é€€å‡ºæç¤ºï¼ˆæ–°å¢ï¼‰
            exit_hint = "\n\nğŸ’™ é—œæ‡·æ¨¡å¼å·²å•Ÿå‹•ã€‚èªªã€Œæˆ‘æ²’äº‹äº†ã€å¯ä»¥é€€å‡ºã€‚"
            return PipelineResult(text=text + exit_hint, is_fallback=False, meta={"care_mode": True, "emotion": emotion_value})

        # 3) æœ‰åŠŸèƒ½ â†’ åŠŸèƒ½è™•ç†(é™æ™‚)
        if has_feature and intent_data:
            feat_res = await self._with_timeout(
                self._feature_processor(intent_data, user_id, user_message, chat_id),
                self._feature_timeout,
                reason="feature",
            )
            if isinstance(feat_res, PipelineResult):
                return feat_res
            # å¦‚æœè¿”å› Noneï¼Œè¡¨ç¤ºé€™æ˜¯èŠå¤©ï¼Œä¸æ‡‰è©²è¢«ç•¶ä½œåŠŸèƒ½è™•ç†
            if feat_res is None:
                has_feature = False
                intent_data = None
            else:
                # æª¢æŸ¥æ˜¯å¦ç‚ºå­—å…¸ï¼ˆåŒ…å«å·¥å…·ä¿¡æ¯ï¼‰
                if isinstance(feat_res, dict):
                    text = feat_res.get('message', feat_res.get('content', '')).strip()
                    tool_name = feat_res.get('tool_name')
                    tool_data = feat_res.get('tool_data')
                    if not text:
                        return PipelineResult(text="æŠ±æ­‰ï¼ŒåŠŸèƒ½è™•ç†æ²’æœ‰ç”¢å‡ºçµæœã€‚", is_fallback=True, reason="feature-empty")

                    # ç°¡åŒ–ç¿»è­¯ï¼šéä¸­æ–‡ç”¨æˆ¶ â†’ ç¿»è­¯å·¥å…·å¡ç‰‡
                    if not self._is_chinese_message(user_message) and tool_data:
                        tool_data = await self._translate_tool_data(tool_data, user_message)

                    # è¿”å›å¸¶æœ‰å·¥å…·å…ƒæ•¸æ“šçš„çµæœï¼ˆåŒ…å«æƒ…ç·’ï¼‰
                    meta_dict = {}
                    if tool_name:
                        meta_dict['tool_name'] = tool_name
                    if tool_data:
                        meta_dict['tool_data'] = tool_data
                    meta_dict['emotion'] = emotion_value

                    return PipelineResult(
                        text=text,
                        is_fallback=False,
                        meta=meta_dict if meta_dict else None
                    )
                else:
                    # æ­£å¸¸å­—ä¸²
                    text = str(feat_res or "").strip()
                    if not text:
                        return PipelineResult(text="æŠ±æ­‰ï¼ŒåŠŸèƒ½è™•ç†æ²’æœ‰ç”¢å‡ºçµæœã€‚", is_fallback=True, reason="feature-empty")

                    # ä¸å†ç¿»è­¯å·¥å…·å›æ‡‰ï¼Œè®“ GPT è‡ªå·±è™•ç†ä¸¦ç”¨å°æ‡‰èªè¨€æè¿°

                    return PipelineResult(
                        text=text,
                        is_fallback=False,
                        meta={"emotion": emotion_value},
                    )

        # 4) ç„¡åŠŸèƒ½ â†’ ä¸€èˆ¬èŠå¤©ï¼ˆé™æ™‚ï¼‰
        # æ³¨æ„ï¼šä¸å‚³ messagesï¼Œæ”¹å‚³ user_messageï¼Œè®“ ai_generator è‡ªå‹•è¼‰å…¥æ­·å²å°è©±å’Œè¨˜æ†¶
        ai_res = await self._with_timeout(
            self._ai_generator(
                user_message,
                user_id or "default",
                self._model,
                request_id,
                chat_id,
                emotion_label=emotion_value,
                language=language,
            ),
            self._ai_timeout,
            reason="ai",
        )
        if isinstance(ai_res, PipelineResult):
            return ai_res
        text = str(ai_res or "").strip()
        if not text:
            return PipelineResult(text="æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚æ²’æœ‰åˆé©çš„å›æ‡‰ã€‚å¯ä»¥æ›å€‹èªªæ³•å†è©¦è©¦å—ï¼Ÿ", is_fallback=True, reason="ai-empty")

        # ä¸€èˆ¬èŠå¤©ä¹ŸåŒ…å«æƒ…ç·’è³‡è¨Šï¼ˆæ–°å¢ï¼‰
        meta_dict = {}
        meta_dict['emotion'] = emotion_value

        return PipelineResult(text=text, is_fallback=False, meta=meta_dict if meta_dict else None)
