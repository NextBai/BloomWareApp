import asyncio
import logging
from dataclasses import dataclass
from typing import Any, Awaitable, Callable, Optional, Dict, Tuple, List

from core.emotion_care_manager import EmotionCareManager

logger = logging.getLogger(__name__)


@dataclass
class PipelineResult:
    text: str
    is_fallback: bool = False
    reason: Optional[str] = None  # e.g., "timeout", "error", "no_intent"
    meta: Optional[Dict[str, Any]] = None


class ChatPipeline:
    """
    éé˜»å¡èŠå¤©è™•ç†ç®¡ç·šï¼Œé€éä¾è³´æ³¨å…¥ä»¥ä¾¿æ¸¬è©¦èˆ‡æ›¿æ›å¯¦ä½œã€‚

    ä¾è³´ï¼ˆçš†ç‚ºå¯ await çš„ callablesï¼‰ï¼š
    - intent_detector(message) -> tuple[bool, intent_data]
    - feature_processor(intent_data, user_id, original_message, chat_id) -> str
    - ai_generator(messages:list[dict], client_id:str, model:str|None, request_id:str|None, chat_id:str|None) -> str
    
    å·²ç§»é™¤æœªä½¿ç”¨çš„ä¾è³´ï¼š
    - memory_manager: çŸ­æœŸè¨˜æ†¶ç®¡ç†ï¼ˆæœªä½¿ç”¨ï¼Œå·²æ”¹ç”¨ memory_systemï¼‰
    - summary_gate: æ‘˜è¦æ±ºç­–ï¼ˆéåº¦ç°¡åŒ–ï¼Œå·²ç§»é™¤ï¼‰
    """

    def __init__(
        self,
        intent_detector: Callable[[str], Awaitable[Tuple[bool, dict]]],
        feature_processor: Callable[[dict, str, str, Optional[str]], Awaitable[Any]],
        ai_generator: Callable[..., Awaitable[str]],
        model: str = "gpt-5-nano",
        detect_timeout: float = 5.0,    # 2025 æœ€ä½³å¯¦è¸ï¼šStructured Outputs é€šå¸¸ 2-3ç§’
        feature_timeout: float = 10.0,  # MCP å·¥å…·å·²æœ‰å…§éƒ¨è¶…æ™‚ï¼ˆ30ç§’ï¼‰
        ai_timeout: float = 12.0,       # é…åˆ Streamingï¼ˆé¦–æ¬¡å›æ‡‰ 0.5-1ç§’ï¼‰
    ) -> None:
        self._intent_detector = intent_detector
        self._feature_processor = feature_processor
        self._ai_generator = ai_generator
        self._detect_timeout = detect_timeout
        self._feature_timeout = feature_timeout
        self._ai_timeout = ai_timeout
        self._model = model

    async def _with_timeout(self, coro: Awaitable[Any], timeout: float, reason: str) -> Any:
        try:
            return await asyncio.wait_for(coro, timeout=timeout)
        except asyncio.TimeoutError:
            return PipelineResult(
                text="æŠ±æ­‰ï¼Œæˆ‘é€™é‚Šæœ‰é»å¿™ç¢Œï¼Œç¨å¾Œå†è©¦å¯ä»¥å—ï¼Ÿ",
                is_fallback=True,
                reason=reason,
                meta={"timeout": timeout},
            )
        except Exception as e:
            return PipelineResult(
                text=f"æŠ±æ­‰ï¼Œè™•ç†æ™‚ç¢°åˆ°ç‹€æ³ï¼š{e}",
                is_fallback=True,
                reason=reason,
                meta={"error": str(e)},
            )

    async def process(
        self,
        user_message: str,
        user_id: Optional[str] = None,
        chat_id: Optional[str] = None,
        request_id: Optional[str] = None,
    ) -> PipelineResult:
        if not user_message or not user_message.strip():
            return PipelineResult(text="æˆ‘æ²’æœ‰æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚", is_fallback=True, reason="empty")

        # 0) æª¢æŸ¥æ˜¯å¦åœ¨é—œæ‡·æ¨¡å¼ï¼ˆæ–°å¢ï¼‰
        if user_id and EmotionCareManager.is_in_care_mode(user_id, chat_id):
            # æª¢æŸ¥æ˜¯å¦è§£é™¤é—œæ‡·æ¨¡å¼
            if EmotionCareManager.check_release(user_id, user_message, chat_id):
                logger.info(f"âœ… ç”¨æˆ¶ {user_id} æƒ…ç·’æ¢å¾©ï¼Œè§£é™¤é—œæ‡·æ¨¡å¼ï¼Œç¹¼çºŒæ­£å¸¸æµç¨‹")
                # è§£é™¤å¾Œç¹¼çºŒæ­£å¸¸æµç¨‹
            else:
                logger.info(f"ğŸ’™ ç”¨æˆ¶ {user_id} åœ¨é—œæ‡·æ¨¡å¼ä¸­ï¼Œè·³éå·¥å…·èª¿ç”¨ï¼Œä½¿ç”¨é—œæ‡· AI")
                # ç›´æ¥ç”¨é—œæ‡·æ¨¡å¼ AI å›æ‡‰ï¼ˆä¸æª¢æ¸¬æ„åœ–ï¼Œä¸èª¿ç”¨å·¥å…·ï¼‰
                care_emotion = EmotionCareManager.get_care_emotion(user_id, chat_id)
                ai_res = await self._with_timeout(
                    self._ai_generator(
                        user_message,
                        user_id,
                        self._model,
                        request_id,
                        chat_id,
                        use_care_mode=True,
                        care_emotion=care_emotion,
                        emotion_label=care_emotion,
                    ),
                    self._ai_timeout,
                    reason="ai-care",
                )
                if isinstance(ai_res, PipelineResult):
                    return ai_res
                text = str(ai_res or "").strip()
                if not text:
                    return PipelineResult(text="æˆ‘åœ¨é€™è£¡é™ªä½ ï¼Œéš¨æ™‚å¯ä»¥èŠèŠã€‚", is_fallback=True, reason="ai-care-empty")
                return PipelineResult(text=text, is_fallback=False, meta={"care_mode": True, "emotion": care_emotion})

        # 1) æ„åœ–åµæ¸¬ï¼ˆé™æ™‚ï¼‰
        detect_res = await self._with_timeout(
            self._intent_detector(user_message), self._detect_timeout, reason="detect"
        )
        if isinstance(detect_res, PipelineResult):
            return detect_res
        has_feature, intent_data = detect_res

        # æå–æƒ…ç·’ï¼ˆæ–°å¢ï¼‰
        emotion = intent_data.get("emotion", "neutral") if intent_data else "neutral"
        emotion_value = emotion or "neutral"
        logger.info(f"ğŸ˜Š ç”¨æˆ¶æƒ…ç·’: {emotion}")

        # æª¢æŸ¥æ˜¯å¦éœ€è¦é€²å…¥é—œæ‡·æ¨¡å¼ï¼ˆæ–°å¢ï¼‰
        if user_id and EmotionCareManager.check_and_enter_care_mode(user_id, emotion, chat_id):
            logger.warning(f"âš ï¸ åµæ¸¬åˆ°æ¥µç«¯æƒ…ç·’ [{emotion}]ï¼Œé€²å…¥é—œæ‡·æ¨¡å¼")
            # ç«‹å³ä½¿ç”¨é—œæ‡·æ¨¡å¼ AI å›æ‡‰
            ai_res = await self._with_timeout(
                self._ai_generator(
                    user_message,
                    user_id,
                    self._model,
                    request_id,
                    chat_id,
                    use_care_mode=True,
                    care_emotion=emotion,
                    emotion_label=emotion,
                ),
                self._ai_timeout,
                reason="ai-care",
            )
            if isinstance(ai_res, PipelineResult):
                return ai_res
            text = str(ai_res or "").strip()
            if not text:
                text = "æˆ‘è½åˆ°äº†ï¼Œæˆ‘åœ¨é€™è£¡é™ªä½ ã€‚"

            # ç¬¬ä¸€æ¬¡é€²å…¥é—œæ‡·æ¨¡å¼æ™‚ï¼Œé™„åŠ é€€å‡ºæç¤ºï¼ˆæ–°å¢ï¼‰
            exit_hint = "\n\nğŸ’™ é—œæ‡·æ¨¡å¼å·²å•Ÿå‹•ã€‚èªªã€Œæˆ‘æ²’äº‹äº†ã€å¯ä»¥é€€å‡ºã€‚"
            return PipelineResult(text=text + exit_hint, is_fallback=False, meta={"care_mode": True, "emotion": emotion})

        # 2) æœ‰åŠŸèƒ½ â†’ åŠŸèƒ½è™•ç†(é™æ™‚)
        if has_feature and intent_data:
            feat_res = await self._with_timeout(
                self._feature_processor(intent_data, user_id, user_message, chat_id),
                self._feature_timeout,
                reason="feature",
            )
            if isinstance(feat_res, PipelineResult):
                return feat_res
            # å¦‚æœè¿”å› Noneï¼Œè¡¨ç¤ºé€™æ˜¯èŠå¤©ï¼Œä¸æ‡‰è©²è¢«ç•¶ä½œåŠŸèƒ½è™•ç†
            if feat_res is None:
                has_feature = False
                intent_data = None
            else:
                # æª¢æŸ¥æ˜¯å¦ç‚ºå­—å…¸ï¼ˆåŒ…å«å·¥å…·ä¿¡æ¯ï¼‰
                if isinstance(feat_res, dict):
                    text = feat_res.get('message', feat_res.get('content', '')).strip()
                    tool_name = feat_res.get('tool_name')
                    tool_data = feat_res.get('tool_data')
                    if not text:
                        return PipelineResult(text="æŠ±æ­‰ï¼ŒåŠŸèƒ½è™•ç†æ²’æœ‰ç”¢å‡ºçµæœã€‚", is_fallback=True, reason="feature-empty")
                    # è¿”å›å¸¶æœ‰å·¥å…·å…ƒæ•¸æ“šçš„çµæœï¼ˆåŒ…å«æƒ…ç·’ï¼‰
                    meta_dict = {}
                    if tool_name:
                        meta_dict['tool_name'] = tool_name
                    if tool_data:
                        meta_dict['tool_data'] = tool_data
                    meta_dict['emotion'] = emotion_value

                    return PipelineResult(
                        text=text,
                        is_fallback=False,
                        meta=meta_dict if meta_dict else None
                    )
                else:
                    # æ­£å¸¸å­—ä¸²
                    text = str(feat_res or "").strip()
                    if not text:
                        return PipelineResult(text="æŠ±æ­‰ï¼ŒåŠŸèƒ½è™•ç†æ²’æœ‰ç”¢å‡ºçµæœã€‚", is_fallback=True, reason="feature-empty")
                    return PipelineResult(
                        text=text,
                        is_fallback=False,
                        meta={"emotion": emotion_value},
                    )

        # 3) ç„¡åŠŸèƒ½ â†’ ä¸€èˆ¬èŠå¤©ï¼ˆé™æ™‚ï¼‰
        # æ³¨æ„ï¼šä¸å‚³ messagesï¼Œæ”¹å‚³ user_messageï¼Œè®“ ai_generator è‡ªå‹•è¼‰å…¥æ­·å²å°è©±å’Œè¨˜æ†¶
        ai_res = await self._with_timeout(
            self._ai_generator(
                user_message,
                user_id or "default",
                self._model,
                request_id,
                chat_id,
                emotion_label=emotion_value,
            ),
            self._ai_timeout,
            reason="ai",
        )
        if isinstance(ai_res, PipelineResult):
            return ai_res
        text = str(ai_res or "").strip()
        if not text:
            return PipelineResult(text="æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚æ²’æœ‰åˆé©çš„å›æ‡‰ã€‚å¯ä»¥æ›å€‹èªªæ³•å†è©¦è©¦å—ï¼Ÿ", is_fallback=True, reason="ai-empty")

        # ä¸€èˆ¬èŠå¤©ä¹ŸåŒ…å«æƒ…ç·’è³‡è¨Šï¼ˆæ–°å¢ï¼‰
        meta_dict = {}
        meta_dict['emotion'] = emotion_value

        return PipelineResult(text=text, is_fallback=False, meta=meta_dict if meta_dict else None)
