"""
æ„åœ–æª¢æ¸¬å™¨
2025 æœ€ä½³å¯¦è¸ï¼šä½¿ç”¨ OpenAI åŸç”Ÿ Function Calling é€²è¡Œæ„åœ–æª¢æ¸¬

æ ¸å¿ƒæ”¹é€²ï¼š
1. ä¸å†ä½¿ç”¨å·¨å¤§çš„ system_prompt æè¿°æ¯å€‹å·¥å…·
2. ç›´æ¥ä½¿ç”¨ OpenAI tools åƒæ•¸å‚³éå·¥å…·å®šç¾©
3. GPT åŸç”Ÿé¸æ“‡å·¥å…·ä¸¦ç”Ÿæˆçµæ§‹åŒ–åƒæ•¸
4. æ–°å¢å·¥å…·åªéœ€è¨»å†Šåˆ° Registryï¼Œä¸éœ€æ›´æ–°ä»»ä½• prompt
"""

import json
import hashlib
import time
import logging
from typing import Dict, Any, Optional, Tuple, List

from core.tool_registry import tool_registry
from core.logging import get_logger

logger = get_logger("core.intent_detector")


class IntentDetector:
    """
    æ„åœ–æª¢æ¸¬å™¨
    
    ä½¿ç”¨ OpenAI åŸç”Ÿ Function Calling é€²è¡Œæ„åœ–æª¢æ¸¬ï¼Œ
    ä¸éœ€è¦è‡ªå®šç¾© prompt æè¿°æ¯å€‹å·¥å…·ã€‚
    """
    
    # æƒ…ç·’åˆ—è¡¨
    EMOTIONS = ["neutral", "happy", "sad", "angry", "fear", "surprise"]
    
    # å¿«å– TTLï¼ˆç§’ï¼‰
    CACHE_TTL = 300.0
    
    def __init__(self):
        self._cache: Dict[str, Tuple[bool, Optional[Dict[str, Any]], float]] = {}
    
    async def detect(
        self,
        message: str,
        user_id: Optional[str] = None,
        include_location_tools: bool = True,
    ) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """
        æª¢æ¸¬ç”¨æˆ¶æ¶ˆæ¯ä¸­çš„æ„åœ–
        
        Args:
            message: ç”¨æˆ¶æ¶ˆæ¯
            user_id: ç”¨æˆ¶ IDï¼ˆç”¨æ–¼æ—¥èªŒï¼‰
            include_location_tools: æ˜¯å¦åŒ…å«éœ€è¦ä½ç½®çš„å·¥å…·
        
        Returns:
            (æ˜¯å¦æª¢æ¸¬åˆ°å·¥å…·èª¿ç”¨, æ„åœ–æ•¸æ“š)
        """
        # æª¢æŸ¥å¿«å–
        cache_key = hashlib.md5(message.encode()).hexdigest()
        if cache_key in self._cache:
            has_intent, intent_data, cached_time = self._cache[cache_key]
            if time.time() - cached_time < self.CACHE_TTL:
                logger.debug(f"ğŸ’¾ æ„åœ–å¿«å–å‘½ä¸­: {message[:50]}...")
                return has_intent, intent_data
            else:
                del self._cache[cache_key]
        
        logger.info(f"ğŸ” æª¢æ¸¬æ„åœ–: \"{message[:100]}...\"")
        
        # æª¢æŸ¥ç‰¹æ®Šå‘½ä»¤
        special_result = self._check_special_commands(message)
        if special_result:
            return special_result
        
        # ä½¿ç”¨ OpenAI Function Calling é€²è¡Œæ„åœ–æª¢æ¸¬
        try:
            result = await self._detect_with_function_calling(
                message,
                include_location_tools=include_location_tools,
            )
            
            # å¯«å…¥å¿«å–
            self._cache[cache_key] = (*result, time.time())
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ„åœ–æª¢æ¸¬å¤±æ•—: {e}")
            # é™ç´šï¼šä½¿ç”¨é—œéµå­—åŒ¹é…
            return self._keyword_fallback(message)
    
    def _check_special_commands(self, message: str) -> Optional[Tuple[bool, Dict[str, Any]]]:
        """æª¢æŸ¥ç‰¹æ®Šå‘½ä»¤"""
        for command in ["åŠŸèƒ½åˆ—è¡¨", "æœ‰ä»€éº¼åŠŸèƒ½", "èƒ½åšä»€éº¼"]:
            if command in message:
                logger.info(f"æª¢æ¸¬åˆ°ç‰¹æ®Šå‘½ä»¤: {command}")
                return True, {
                    "type": "special_command",
                    "command": "feature_list"
                }
        return None
    
    async def _detect_with_function_calling(
        self,
        message: str,
        include_location_tools: bool = True,
    ) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """
        ä½¿ç”¨ OpenAI Function Calling é€²è¡Œæ„åœ–æª¢æ¸¬
        
        æ ¸å¿ƒé‚è¼¯ï¼š
        1. å°‡æ‰€æœ‰å·¥å…·ä»¥ OpenAI tools æ ¼å¼å‚³é
        2. GPT è‡ªå‹•é¸æ“‡æœ€é©åˆçš„å·¥å…·
        3. å¦‚æœ GPT ä¸é¸æ“‡ä»»ä½•å·¥å…·ï¼Œè¦–ç‚ºä¸€èˆ¬èŠå¤©
        """
        import services.ai_service as ai_service
        from core.reasoning_strategy import get_optimal_reasoning_effort
        
        # å–å¾—æ‰€æœ‰å·¥å…·å®šç¾©ï¼ˆOpenAI æ ¼å¼ï¼‰
        tools = tool_registry.get_openai_tools(
            include_location_tools=include_location_tools,
            strict=True,
        )
        
        if not tools:
            logger.warning("âš ï¸ æ²’æœ‰å¯ç”¨çš„å·¥å…·")
            return False, {"emotion": "neutral"}
        
        # å»ºæ§‹ç²¾ç°¡çš„ system promptï¼ˆåªè™•ç†æƒ…ç·’å’Œç‰¹æ®Šè¦å‰‡ï¼‰
        system_prompt = self._build_system_prompt()
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ]
        
        # ä½¿ç”¨ OpenAI Function Calling
        optimal_effort = get_optimal_reasoning_effort("intent_detection")
        logger.info(f"ğŸ§  æ„åœ–æª¢æ¸¬æ¨ç†å¼·åº¦: {optimal_effort}")
        
        try:
            response = await ai_service.generate_response_with_tools(
                messages=messages,
                tools=tools,
                user_id="intent_detection",
                model="gpt-5-nano",
                reasoning_effort=optimal_effort,
            )
            
            return self._parse_function_calling_response(response)
            
        except Exception as e:
            logger.error(f"âŒ Function Calling å¤±æ•—: {e}")
            raise
    
    def _build_system_prompt(self) -> str:
        """
        å»ºæ§‹ç²¾ç°¡çš„ system prompt
        
        æ³¨æ„ï¼šä¸å†æè¿°æ¯å€‹å·¥å…·ï¼Œå·¥å…·å®šç¾©ç”± tools åƒæ•¸å‚³é
        """
        return """ä½ æ˜¯ä¸€å€‹å¤šèªè¨€æ™ºèƒ½åŠ©æ‰‹ï¼Œæ ¹æ“šç”¨æˆ¶éœ€æ±‚é¸æ“‡åˆé©çš„å·¥å…·ã€‚æ”¯æ´ä¸­æ–‡ã€è‹±æ–‡ã€æ—¥æ–‡ã€å°å°¼æ–‡ã€è¶Šå—æ–‡ã€‚

ã€æ ¸å¿ƒè¦å‰‡ã€‘
1. ç”¨æˆ¶è©¢å•ä»»ä½•å¯ç”¨å·¥å…·èƒ½è§£æ±ºçš„éœ€æ±‚æ™‚ï¼Œå¿…é ˆé¸æ“‡å°æ‡‰å·¥å…·
2. åªæœ‰ç´”ç²¹çš„é–’èŠã€å•å€™ã€æƒ…æ„Ÿè¡¨é”æ‰ä¸é¸æ“‡å·¥å…·
3. å·¥å…·åƒæ•¸ç›¡é‡å¾ç”¨æˆ¶æ¶ˆæ¯ä¸­æå–ï¼Œç„¡æ³•ç¢ºå®šçš„ä½¿ç”¨åˆç†é è¨­å€¼

ã€å¤šèªè¨€æ„åœ–è­˜åˆ¥ã€‘
ç„¡è«–ç”¨æˆ¶ä½¿ç”¨ä»€éº¼èªè¨€ï¼Œéƒ½è¦è­˜åˆ¥ä»¥ä¸‹æ„åœ–ä¸¦é¸æ“‡å°æ‡‰å·¥å…·ï¼š

å¤©æ°£æŸ¥è©¢ï¼ˆweather_queryï¼‰ï¼š
- ä¸­æ–‡ï¼šå¤©æ°£ã€æ°£æº«ã€æœƒä¸‹é›¨å—ã€ä»Šå¤©ç†±å—
- è‹±æ–‡ï¼šweather, temperature, rain, hot today, forecast
- æ—¥æ–‡ï¼šå¤©æ°—ã€æ°—æ¸©ã€é›¨ã€æš‘ã„
- å°å°¼æ–‡ï¼šcuaca, suhu, hujan
- è¶Šå—æ–‡ï¼šthá»i tiáº¿t, nhiá»‡t Ä‘á»™, mÆ°a

åŒ¯ç‡æŸ¥è©¢ï¼ˆexchange_rateï¼‰ï¼š
- ä¸­æ–‡ï¼šåŒ¯ç‡ã€æ›ç®—ã€å¤šå°‘éŒ¢
- è‹±æ–‡ï¼šexchange rate, convert, currency
- æ—¥æ–‡ï¼šç‚ºæ›¿ã€ä¸¡æ›¿
- å°å°¼æ–‡ï¼škurs, tukar
- è¶Šå—æ–‡ï¼štá»· giÃ¡, Ä‘á»•i tiá»n

æ–°èæŸ¥è©¢ï¼ˆnews_searchï¼‰ï¼š
- ä¸­æ–‡ï¼šæ–°èã€é ­æ¢ã€æœ€æ–°æ¶ˆæ¯
- è‹±æ–‡ï¼šnews, headlines, latest
- æ—¥æ–‡ï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹ã€æœ€æ–°
- å°å°¼æ–‡ï¼šberita, terbaru
- è¶Šå—æ–‡ï¼štin tá»©c, má»›i nháº¥t

ã€åƒæ•¸è™•ç†ã€‘
- å¤©æ°£æŸ¥è©¢ï¼šåŸå¸‚åç¨±ä½¿ç”¨è‹±æ–‡ï¼ˆå°åŒ—â†’Taipei, æ±äº¬â†’Tokyo, Jakarta, Hanoiï¼‰
- åŒ¯ç‡æŸ¥è©¢ï¼šè²¨å¹£ä½¿ç”¨ ISO 4217 ä»£ç¢¼ï¼ˆUSD, TWD, JPY, IDR, VNDï¼‰
- å…¬è»ŠæŸ¥è©¢ï¼šroute_name å¿…é ˆæ˜¯è·¯ç·šè™Ÿç¢¼ï¼ˆå¦‚ 307ã€ç´…30ï¼‰
- ç«è»ŠæŸ¥è©¢ï¼šã€Œå¾€XXã€è¡¨ç¤º destination_station
- ä½ç½®æŸ¥è©¢ï¼šã€Œæˆ‘åœ¨å“ªã€ã€Œwhere am Iã€ä½¿ç”¨ reverse_geocode
- YouBike æŸ¥è©¢ï¼šYouBike/Ubike/å¾®ç¬‘å–®è»Š ä½¿ç”¨ tdx_youbike

ã€æƒ…ç·’åˆ¤æ–·ã€‘
æ ¹æ“šç”¨æˆ¶æ¶ˆæ¯çš„èªæ°£åˆ¤æ–·æƒ…ç·’ï¼š
- neutral: å¹³éœã€ä¸­æ€§
- happy: é–‹å¿ƒã€èˆˆå¥®
- sad: é›£éã€æ²®å–ª
- angry: ç”Ÿæ°£ã€ç…©èº
- fear: ææ‡¼ã€æ“”å¿ƒ
- surprise: é©šè¨ã€æ„å¤–"""
    
    def _parse_function_calling_response(
        self,
        response: Dict[str, Any],
    ) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """
        è§£æ Function Calling å›æ‡‰
        
        Args:
            response: OpenAI API å›æ‡‰
        
        Returns:
            (æ˜¯å¦æª¢æ¸¬åˆ°å·¥å…·èª¿ç”¨, æ„åœ–æ•¸æ“š)
        """
        # æª¢æŸ¥æ˜¯å¦æœ‰ tool_calls
        tool_calls = response.get("tool_calls", [])
        
        if tool_calls:
            # å–ç¬¬ä¸€å€‹å·¥å…·èª¿ç”¨
            tool_call = tool_calls[0]
            function = tool_call.get("function", {})
            tool_name = function.get("name", "")
            arguments_str = function.get("arguments", "{}")
            
            try:
                arguments = json.loads(arguments_str)
            except json.JSONDecodeError:
                arguments = {}
            
            logger.info(f"âœ… GPT é¸æ“‡å·¥å…·: {tool_name}")
            logger.debug(f"å·¥å…·åƒæ•¸: {arguments}")
            
            # æå–æƒ…ç·’ï¼ˆå¾ content æˆ–é è¨­ï¼‰
            emotion = self._extract_emotion_from_response(response)
            
            return True, {
                "type": "mcp_tool",
                "tool_name": tool_name,
                "arguments": arguments,
                "emotion": emotion,
            }
        
        # æ²’æœ‰å·¥å…·èª¿ç”¨ï¼Œè¦–ç‚ºä¸€èˆ¬èŠå¤©
        logger.info("ğŸ’¬ GPT åˆ¤æ–·ç‚ºä¸€èˆ¬èŠå¤©")
        emotion = self._extract_emotion_from_response(response)
        
        return False, {"emotion": emotion}
    
    def _extract_emotion_from_response(self, response: Dict[str, Any]) -> str:
        """å¾å›æ‡‰ä¸­æå–æƒ…ç·’"""
        # å˜—è©¦å¾ content ä¸­æå–
        content = response.get("content", "")
        if content:
            for emotion in self.EMOTIONS:
                if emotion in content.lower():
                    return emotion
        
        return "neutral"
    
    def _keyword_fallback(self, message: str) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """é—œéµå­—åŒ¹é…é™ç´šæ–¹æ¡ˆ"""
        message_lower = message.lower()
        
        # å–å¾—æ‰€æœ‰å·¥å…·æ‘˜è¦
        summaries = tool_registry.get_summaries()
        
        for summary in summaries:
            keywords = summary.get("keywords", [])
            for keyword in keywords:
                if keyword.lower() in message_lower:
                    logger.info(f"ğŸ”‘ é—œéµå­—åŒ¹é…: {keyword} â†’ {summary['name']}")
                    return True, {
                        "type": "mcp_tool",
                        "tool_name": summary["name"],
                        "arguments": {},
                        "emotion": "neutral",
                    }
        
        return False, {"emotion": "neutral"}
    
    def clear_cache(self) -> None:
        """æ¸…é™¤å¿«å–"""
        self._cache.clear()
        logger.info("ğŸ—‘ï¸ æ„åœ–å¿«å–å·²æ¸…é™¤")


# å…¨åŸŸå–®ä¾‹
intent_detector = IntentDetector()
