"""
æ–°èæŸ¥è©¢ MCP Tool
ä½¿ç”¨ NewsData.io å¯¦ä½œçš„æ–°èåŠŸèƒ½ï¼Œæä¾›æ›´å¯é çš„å°ç£èˆ‡ç¹ä¸­æ–°è
"""

import os
import json
import logging
import aiohttp
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from urllib.parse import quote
from dotenv import load_dotenv
from .base_tool import MCPTool, ValidationError, ExecutionError, StandardToolSchemas

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# çµ±ä¸€é…ç½®ç®¡ç†
from core.config import settings

logger = logging.getLogger("mcp.tools.news")

# NewsData.io é…ç½®
NEWSDATA_BASE_URL = "https://newsdata.io/api/1"
NEWSDATA_API_KEY = settings.NEWSDATA_API_KEY


class NewsTool(MCPTool):
    """æ–°èæŸ¥è©¢ MCP å·¥å…· - ä½¿ç”¨ NewsData.ioï¼ˆæ›´å¥½çš„å°ç£èˆ‡ç¹ä¸­æ–°èæ”¯æ´ï¼‰"""

    NAME = "news_query"
    DESCRIPTION = "Query latest news articles (can specify category, language, and quantity)"
    CATEGORY = "ç”Ÿæ´»è³‡è¨Š"
    TAGS = ["news", "æ–°è", "è³‡è¨Š"]
    KEYWORDS = ["æ–°è", "æ¶ˆæ¯", "å ±å°", "news", "é ­æ¢", "æ™‚äº‹"]
    USAGE_TIPS = [
        "å¯æŒ‡å®šæ–°èé¡åˆ¥ï¼ˆç§‘æŠ€ã€å•†æ¥­ã€å¨›æ¨‚ç­‰ï¼‰",
        "æ”¯æ´å¤šåœ‹æ–°èï¼ˆå°ç£ã€ç¾åœ‹ã€æ—¥æœ¬ç­‰ï¼‰",
        "å¯é™åˆ¶è¿”å›æ•¸é‡"
    ]

    @classmethod
    def get_input_schema(cls) -> Dict[str, Any]:
        """ç²å–è¼¸å…¥åƒæ•¸æ¨¡å¼"""
        return StandardToolSchemas.create_input_schema({
            "query": {
                "type": "string",
                "description": "æœå°‹é—œéµè©ï¼ˆå¯é¸ï¼‰"
            },
            "country": {
                "type": "string",
                "description": "æ–°èåœ‹å®¶ä»£ç¢¼ (tw, us, cn, jp, kr, hk, sg)",
                "default": "tw",
                "enum": ["tw", "us", "cn", "jp", "kr", "hk", "sg", "gb", "de", "fr"]
            },
            "category": {
                "type": "string",
                "description": "æ–°èåˆ†é¡ (business, technology, health, science, sports, entertainment, top)",
                "default": "top",
                "enum": ["business", "technology", "health", "science", "sports", "entertainment", "top", "world", "politics"]
            },
            "language": {
                "type": "string",
                "description": "æ–°èèªè¨€ (zh, en, ja, ko)",
                "default": "zh",
                "enum": ["zh", "en", "ja", "ko"]
            },
            "limit": {
                "type": "integer",
                "description": "è¿”å›æ–°èæ•¸é‡é™åˆ¶ï¼ˆå…è²»ç‰ˆæœ€å¤š 10ï¼‰",
                "default": 10,
                "minimum": 1,
                "maximum": 10
            },
            "timeframe": {
                "type": "integer",
                "description": "æŸ¥è©¢éå»å¹¾å°æ™‚çš„æ–°èï¼ˆ1-48ï¼Œå¯é¸ï¼‰",
                "minimum": 1,
                "maximum": 48
            }
        })

    @classmethod
    def get_output_schema(cls) -> Dict[str, Any]:
        """ç²å–è¼¸å‡ºçµæœæ¨¡å¼"""
        base_schema = StandardToolSchemas.create_output_schema()
        base_schema["properties"].update({
            "articles": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "article_id": {"type": "string"},
                        "title": {"type": "string"},
                        "description": {"type": "string"},
                        "content": {"type": "string"},
                        "url": {"type": "string"},
                        "published_at": {"type": "string"},
                        "source": {
                            "type": "object",
                            "properties": {
                                "name": {"type": "string"},
                                "id": {"type": "string"},
                                "url": {"type": "string"}
                            }
                        },
                        "category": {"type": "array"},
                        "language": {"type": "string"},
                        "sentiment": {"type": "string"}
                    }
                }
            },
            "count": {"type": "integer"},
            "totalResults": {"type": "integer"}
        })
        return base_schema

    @classmethod
    async def execute(cls, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """åŸ·è¡Œæ–°èæŸ¥è©¢"""
        if not NEWSDATA_API_KEY:
            return cls.create_error_response(
                error="NewsData.io API é‡‘é‘°æœªè¨­ç½®ï¼Œè«‹è¨­ç½® NEWSDATA_API_KEY ç’°å¢ƒè®Šæ•¸",
                code="API_KEY_MISSING"
            )

        # è™•ç†åƒæ•¸ï¼Œéæ¿¾ç©ºå­—ä¸²ä¸¦ä½¿ç”¨é è¨­å€¼
        query = arguments.get("query", "")
        country = arguments.get("country", "tw") or "tw"
        category = arguments.get("category", "top") or "top"
        language = arguments.get("language", "zh") or "zh"
        limit = min(arguments.get("limit", 10), 10)  # å…è²»ç‰ˆé™åˆ¶ 10
        timeframe = arguments.get("timeframe")

        # ç¢ºä¿ category æ˜¯æœ‰æ•ˆå€¼ï¼ˆé˜²æ­¢ç©ºå­—ä¸²ï¼‰
        valid_categories = ["business", "technology", "health", "science", "sports", "entertainment", "top", "world", "politics"]
        if category not in valid_categories:
            category = "top"

        try:
            news_data = await cls._fetch_news_from_newsdata(
                query, country, category, language, limit, timeframe
            )

            if news_data.get("success"):
                articles = news_data.get("articles", [])
                total_results = news_data.get("totalResults", 0)

                # ç‚ºæ¯ç¯‡æ–°èç”Ÿæˆç°¡çŸ­æ‘˜è¦ï¼ˆç”¨æ–¼å·¥å…·å¡ç‰‡é¡¯ç¤ºï¼‰
                articles = await cls._generate_summaries(articles)

                formatted_text = cls._format_newsdata_response(
                    articles, query, country, category, total_results
                )

                return cls.create_success_response(
                    content=formatted_text,
                    data={
                        "raw_data": {
                            "articles": articles,
                            "count": len(articles),
                            "totalResults": total_results
                        }
                    }
                )
            else:
                return cls.create_error_response(
                    error=news_data.get("error", "ç²å–æ–°èå¤±æ•—"),
                    code="FETCH_ERROR"
                )

        except Exception as e:
            logger.error(f"æ–°èæŸ¥è©¢éŒ¯èª¤: {e}")
            raise ExecutionError(f"æ–°èæŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}", e)

    @staticmethod
    async def _fetch_news_from_newsdata(
        query: str, country: str, category: str,
        language: str, limit: int, timeframe: Optional[int]
    ) -> Dict[str, Any]:
        """å¾ NewsData.io ç²å–æ–°èæ•¸æ“š"""
        try:
            # å»ºæ§‹ NewsData.io URL
            url = f"{NEWSDATA_BASE_URL}/latest"

            # æ§‹å»ºåƒæ•¸
            params = {
                "apikey": NEWSDATA_API_KEY,
                "size": limit,
                "language": language
            }

            # é—œéµå­—æœå°‹
            if query:
                params["q"] = query

            # åœ‹å®¶ç¯©é¸ï¼ˆåƒ…åœ¨æ²’æœ‰é—œéµå­—æ™‚ä½¿ç”¨ï¼‰
            if country and not query:
                params["country"] = country

            # åˆ†é¡ç¯©é¸
            if category and category != "top":
                params["category"] = category

            # æ™‚é–“ç¯„åœ
            if timeframe:
                params["timeframe"] = timeframe

            # æ’é™¤é‡è¤‡
            params["removeduplicate"] = "1"

            logger.info(f"NewsData.io è«‹æ±‚: {url}")
            logger.info(f"åƒæ•¸: {', '.join([f'{k}={v}' for k, v in params.items() if k != 'apikey'])}")

            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, timeout=15) as response:
                    logger.info(f"NewsData.io éŸ¿æ‡‰ç‹€æ…‹: {response.status}")

                    if response.status == 200:
                        data = await response.json()

                        # æª¢æŸ¥ API å›æ‡‰ç‹€æ…‹
                        status = data.get("status")
                        if status == "success":
                            articles = data.get("results", [])
                            total_results = data.get("totalResults", 0)

                            logger.info(f"NewsData.io è¿”å›æ–‡ç« æ•¸: {len(articles)} / ç¸½æ•¸: {total_results}")

                            # è™•ç†æ–‡ç« æ•¸æ“šï¼ˆç¢ºä¿èˆ‡å‰ç«¯æ ¼å¼å…¼å®¹ï¼‰
                            processed_articles = []
                            for article in articles:
                                source_name = article.get("source_name", article.get("source_id", "æœªçŸ¥ä¾†æº"))

                                # éæ¿¾æ‰ä»˜è²»åŠŸèƒ½çš„ä½”ä½æ–‡å­—
                                sentiment = article.get("sentiment", "")
                                if "ONLY AVAILABLE" in str(sentiment):
                                    sentiment = ""

                                content = article.get("content", "")
                                if "ONLY AVAILABLE" in str(content):
                                    content = ""

                                processed_article = {
                                    "article_id": article.get("article_id", ""),
                                    "title": article.get("title", "ç„¡æ¨™é¡Œ"),
                                    "description": article.get("description", ""),
                                    "content": content,
                                    "url": article.get("link", ""),
                                    "published_at": article.get("pubDate", ""),
                                    # å‰ç«¯æœŸæœ› source æ˜¯ç‰©ä»¶ {name: "ä¾†æºå"}ï¼Œæˆ–å­—ä¸²ç›´æ¥é¡¯ç¤º
                                    "source": {
                                        "name": source_name,
                                        "id": article.get("source_id", ""),
                                        "url": article.get("source_url", "")
                                    },
                                    "category": article.get("category", []),
                                    "language": article.get("language", ""),
                                    "country": article.get("country", []),
                                    "sentiment": sentiment,
                                    "image_url": article.get("image_url", "")
                                }
                                processed_articles.append(processed_article)

                            return {
                                "success": True,
                                "articles": processed_articles,
                                "totalResults": total_results
                            }
                        else:
                            # API è¿”å›éŒ¯èª¤ç‹€æ…‹
                            error_msg = data.get("results", {}).get("message", "æœªçŸ¥éŒ¯èª¤")
                            error_code = data.get("results", {}).get("code", "UNKNOWN")
                            logger.error(f"NewsData.io API éŒ¯èª¤: {error_code} - {error_msg}")
                            return {
                                "success": False,
                                "error": f"API éŒ¯èª¤: {error_msg}"
                            }

                    elif response.status == 401:
                        return {
                            "success": False,
                            "error": "NewsData.io API é‡‘é‘°ç„¡æ•ˆæˆ–å·²éæœŸ"
                        }
                    elif response.status == 429:
                        return {
                            "success": False,
                            "error": "NewsData.io API è«‹æ±‚æ¬¡æ•¸å·²é”ä¸Šé™ï¼ˆå…è²»ç‰ˆæ¯æ—¥ 200 æ¬¡ï¼‰"
                        }
                    else:
                        error_text = await response.text()
                        logger.error(f"NewsData.io HTTP éŒ¯èª¤ {response.status}: {error_text}")
                        return {
                            "success": False,
                            "error": f"HTTP éŒ¯èª¤: {response.status}"
                        }

        except asyncio.TimeoutError:
            return {
                "success": False,
                "error": "NewsData.io è«‹æ±‚è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦"
            }
        except aiohttp.ClientError as e:
            logger.error(f"ç¶²çµ¡é€£æ¥éŒ¯èª¤: {e}")
            return {
                "success": False,
                "error": "ç¶²çµ¡é€£æ¥éŒ¯èª¤ï¼Œç„¡æ³•ç²å–æ–°è"
            }
        except Exception as e:
            logger.error(f"NewsData.io è«‹æ±‚éŒ¯èª¤: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }

    @staticmethod
    async def _generate_summaries(articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç‚ºæ¯ç¯‡æ–°èç”Ÿæˆä¸€å¥è©±ç°¡çŸ­æ‘˜è¦ï¼ˆç”¨æ–¼å·¥å…·å¡ç‰‡é¡¯ç¤ºï¼‰"""
        try:
            from services.ai_service import generate_response_async

            logger.info(f"ğŸ¤– é–‹å§‹ç‚º {len(articles)} å‰‡æ–°èç”Ÿæˆæ‘˜è¦")

            # æ‰¹é‡è™•ç†ï¼šä¸€æ¬¡è«‹æ±‚è™•ç†æ‰€æœ‰æ–°è
            news_items = []
            for idx, article in enumerate(articles, 1):
                title = article.get("title", "")
                description = article.get("description", "")

                if not title:
                    article["summary"] = "ç„¡æ¨™é¡Œ"
                    continue

                # çµ„åˆæ¨™é¡Œå’Œæè¿°
                content = f"{idx}. æ¨™é¡Œï¼š{title}"
                if description:
                    content += f"\n   æè¿°ï¼š{description[:100]}"
                news_items.append(content)

            if not news_items:
                return articles

            # ä¸€æ¬¡æ€§è«‹æ±‚ AI ç”Ÿæˆæ‰€æœ‰æ‘˜è¦
            batch_prompt = "\n\n".join(news_items)

            try:
                response = await generate_response_async(
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯æ–°èæ‘˜è¦åŠ©æ‰‹ã€‚è«‹ç‚ºæ¯å‰‡æ–°èç”Ÿæˆä¸€å¥è©±æ‘˜è¦ï¼ˆæœ€å¤š30å­—ï¼‰ï¼Œç”¨æ•¸å­—ç·¨è™Ÿå›æ‡‰ã€‚"
                        },
                        {
                            "role": "user",
                            "content": f"è«‹ç‚ºä»¥ä¸‹æ–°èå„ç”Ÿæˆä¸€å¥è©±æ‘˜è¦ï¼ˆæ¯å‰‡æœ€å¤š30å­—ï¼‰ï¼š\n\n{batch_prompt}"
                        }
                    ],
                    model="gpt-5-nano",
                    reasoning_effort="low"
                )

                # è§£æå›æ‡‰
                lines = response.strip().split('\n')
                summaries = []
                for line in lines:
                    line = line.strip()
                    # ç§»é™¤ç·¨è™Ÿå‰ç¶´ (1. 2. ç­‰)
                    if line and (line[0].isdigit() or line.startswith('â€¢') or line.startswith('-')):
                        # å»é™¤ç·¨è™Ÿå’Œæ¨™é»
                        summary = line.lstrip('0123456789.-â€¢) ').strip()
                        if summary:
                            summaries.append(summary[:30])  # é™åˆ¶ 30 å­—

                # å°‡æ‘˜è¦åˆ†é…çµ¦æ–‡ç« 
                for idx, article in enumerate(articles):
                    if article.get("title"):
                        if idx < len(summaries):
                            article["summary"] = summaries[idx]
                            logger.info(f"ğŸ“ æ–°è{idx+1} æ‘˜è¦: {summaries[idx]} ({len(summaries[idx])}å­—)")
                        else:
                            # Fallback
                            title = article.get("title", "")
                            article["summary"] = title[:30]
                            logger.warning(f"âš ï¸ æ–°è{idx+1} ä½¿ç”¨ fallback")

            except Exception as e:
                logger.error(f"AI ç”Ÿæˆæ‘˜è¦å¤±æ•—: {e}")
                # Fallback: ä½¿ç”¨æ¨™é¡Œ
                for article in articles:
                    title = article.get("title", "ç„¡æ¨™é¡Œ")
                    article["summary"] = title[:30]

            return articles

        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆæ‘˜è¦å¤±æ•—: {e}")
            # å¤±æ•—æ™‚ä½¿ç”¨æ¨™é¡Œä½œç‚º fallback
            for article in articles:
                if "summary" not in article:
                    title = article.get("title", "ç„¡æ¨™é¡Œ")
                    article["summary"] = title[:30]
            return articles

    @staticmethod
    def _format_newsdata_response(
        articles: List[Dict[str, Any]], query: str,
        country: str, category: str, total_results: int
    ) -> str:
        """æ ¼å¼åŒ– NewsData.io å›æ‡‰"""
        if not articles:
            return "æŠ±æ­‰ï¼Œæ‰¾ä¸åˆ°ç›¸é—œæ–°è"

        # æ¨™é¡Œ
        header = "ğŸ“° æœ€æ–°æ–°è"
        if query:
            header += f" - æœå°‹: {query}"
        else:
            country_names = {
                "tw": "å°ç£", "us": "ç¾åœ‹", "cn": "ä¸­åœ‹",
                "jp": "æ—¥æœ¬", "kr": "éŸ“åœ‹", "hk": "é¦™æ¸¯",
                "sg": "æ–°åŠ å¡", "gb": "è‹±åœ‹", "de": "å¾·åœ‹", "fr": "æ³•åœ‹"
            }
            header += f" - {country_names.get(country, country.upper())}"

        if category and category != "top":
            category_names = {
                "business": "å•†æ¥­", "technology": "ç§‘æŠ€",
                "health": "å¥åº·", "science": "ç§‘å­¸",
                "sports": "é«”è‚²", "entertainment": "å¨›æ¨‚",
                "world": "åœ‹éš›", "politics": "æ”¿æ²»"
            }
            header += f" - {category_names.get(category, category)}"

        result = f"{header}\n\n"

        # æ–°èåˆ—è¡¨
        for i, article in enumerate(articles, 1):
            result += f"ğŸ“Œ {article.get('title', 'ç„¡æ¨™é¡Œ')}\n"

            # ä¾†æºï¼ˆå…¼å®¹ç‰©ä»¶å’Œå­—ä¸²æ ¼å¼ï¼‰
            source = article.get('source', {})
            if isinstance(source, dict):
                source_name = source.get('name', 'æœªçŸ¥ä¾†æº')
            else:
                source_name = source or 'æœªçŸ¥ä¾†æº'
            result += f"ğŸ—ï¸ {source_name}"

            # åˆ†é¡æ¨™ç±¤
            categories = article.get('category', [])
            if categories:
                category_str = ", ".join(categories[:2])  # æœ€å¤šé¡¯ç¤º 2 å€‹åˆ†é¡
                result += f" | ğŸ·ï¸ {category_str}"

            # æƒ…ç·’æ¨™ç±¤ï¼ˆéæ¿¾ä»˜è²»åŠŸèƒ½æç¤ºï¼‰
            sentiment = article.get('sentiment', '')
            if sentiment and "ONLY AVAILABLE" not in str(sentiment):
                sentiment_emoji = {
                    "positive": "ğŸ˜Š æ­£é¢",
                    "neutral": "ğŸ˜ ä¸­ç«‹",
                    "negative": "ğŸ˜Ÿ è² é¢"
                }.get(sentiment.lower(), sentiment)
                result += f" | {sentiment_emoji}"

            result += "\n"

            # ç™¼å¸ƒæ™‚é–“
            published_at = article.get('published_at', '')
            if published_at:
                try:
                    # NewsData.io æ ¼å¼: "2025-01-25 12:34:56"
                    if ' ' in published_at:
                        dt = datetime.strptime(published_at, '%Y-%m-%d %H:%M:%S')
                        formatted_date = dt.strftime('%m/%d %H:%M')
                        result += f"ğŸ“… {formatted_date}\n"
                    else:
                        result += f"ğŸ“… {published_at[:16]}\n"
                except Exception as e:
                    logger.warning(f"æ—¥æœŸè§£æéŒ¯èª¤: {e}")
                    result += f"ğŸ“… {published_at[:16]}\n"

            # æè¿°
            description = article.get('description', '')
            if description:
                if len(description) > 150:
                    description = description[:150] + "..."
                result += f"ğŸ“ {description}\n"

            # é€£çµ
            url = article.get('url', '')
            if url:
                result += f"ğŸ”— {url}\n"

            result += "\n"

        # åº•éƒ¨è³‡è¨Š
        result += f"ğŸ“Š é¡¯ç¤º {len(articles)} å‰‡ / å…± {total_results} å‰‡æ–°è | ğŸ•’ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        result += "\nğŸ’¡ ç”± NewsData.io æä¾›"

        return result
