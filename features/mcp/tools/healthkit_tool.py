"""
HealthKit å·¥å…· - å¾æ•¸æ“šåº«æŸ¥è©¢å¥åº·æ•¸æ“š
æä¾›é›²ç«¯åŒæ­¥çš„å¥åº·æ•¸æ“šæŸ¥è©¢åŠŸèƒ½
"""

import json
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta

from .base_tool import MCPTool, ValidationError, ExecutionError
from google.cloud import firestore
from google.cloud.firestore_v1 import FieldFilter

logger = logging.getLogger("mcp.tools.healthkit")
logger.setLevel(logging.DEBUG)  # å¼·åˆ¶è¨­ç½®ç‚º DEBUG ç´šåˆ¥


class HealthKitTool(MCPTool):
    """HealthKit å¥åº·æ•¸æ“šæŸ¥è©¢å·¥å…· - å¾æ•¸æ“šåº«è®€å–"""
    
    NAME = "healthkit_query"
    DESCRIPTION = "æŸ¥è©¢ç”¨æˆ¶çš„å¥åº·æ•¸æ“šï¼ŒåŒ…æ‹¬å¿ƒç‡ã€æ­¥æ•¸ã€è¡€æ°§ã€å‘¼å¸é »ç‡ç­‰ï¼ˆæ•¸æ“šç”±iOSè¨­å‚™è‡ªå‹•åŒæ­¥åˆ°Firestoreï¼‰"
    CATEGORY = "å¥åº·æ•¸æ“š"
    TAGS = ["health", "fitness", "database", "firestore"]
    KEYWORDS = ["å¥åº·", "å¿ƒç‡", "æ­¥æ•¸", "è¡€æ°§", "ç¡çœ ", "health", "é‹å‹•", "å¡è·¯é‡Œ", "å‘¼å¸"]
    USAGE_TIPS = [
        "å¯æŸ¥è©¢å¿ƒç‡ã€æ­¥æ•¸ã€è¡€æ°§ã€å‘¼å¸é »ç‡ã€ç¡çœ ç­‰",
        "æ”¯æ´æŒ‡å®šæŸ¥è©¢å¤©æ•¸ï¼ˆ1-365å¤©ï¼‰",
        "æ•¸æ“šç”± iOS è¨­å‚™è‡ªå‹•åŒæ­¥"
    ]
    
    def __init__(self):
        super().__init__()
        self.name = self.NAME
        self.description = self.DESCRIPTION
        self.category = self.CATEGORY
        self.tags = self.TAGS
    
    @classmethod
    def get_input_schema(cls) -> Dict[str, Any]:
        """ç²å–è¼¸å…¥åƒæ•¸æ¨¡å¼"""
        return {
            "type": "object",
            "properties": {
                "user_id": {
                    "type": "string",
                    "description": "ç”¨æˆ¶ IDï¼ˆå¯é¸ï¼Œä¸æä¾›æ™‚ä½¿ç”¨ç•¶å‰ç”¨æˆ¶ï¼‰"
                },
                "metric_type": {
                    "type": "string",
                    "description": "è¦æŸ¥è©¢çš„å¥åº·æŒ‡æ¨™é¡å‹",
                    "enum": ["all", "heart_rate", "step_count", "oxygen_level", "respiratory_rate", "sleep_analysis"],
                    "default": "all"
                },
                "days": {
                    "type": "integer",
                    "description": "æŸ¥è©¢éå»å¤šå°‘å¤©çš„æ•¸æ“š",
                    "default": 7,
                    "minimum": 1,
                    "maximum": 365
                },
                "latest_only": {
                    "type": "boolean",
                    "description": "æ˜¯å¦åªè¿”å›æœ€æ–°çš„ä¸€ç­†æ•¸æ“š",
                    "default": False
                },
                "aggregation": {
                    "type": "string",
                    "description": "æ•¸æ“šèšåˆæ–¹å¼",
                    "enum": ["none", "daily", "weekly"],
                    "default": "none"
                }
            },
            "required": []
        }
    
    @classmethod
    def get_output_schema(cls) -> Dict[str, Any]:
        """ç²å–è¼¸å‡ºçµæœæ¨¡å¼"""
        return {
            "type": "object",
            "properties": {
                "status": {"type": "string"},
                "data": {"type": "array"},
                "count": {"type": "integer"},
                "message": {"type": "string"},
                "metadata": {"type": "object"}
            }
        }
    
    @classmethod
    async def execute(cls, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """å¾æ•¸æ“šåº«æŸ¥è©¢å¥åº·æ•¸æ“š"""
        logger.info("ğŸ” æ”¶åˆ° HealthKit æŸ¥è©¢è«‹æ±‚: %s", json.dumps(arguments, ensure_ascii=False))

        try:
            # å¾æ¨¡çµ„å–å¾— firestore_db å¯¦ä¾‹ï¼ˆæ‡‰ç”¨å•Ÿå‹•æ™‚å·²ç¢ºä¿é€£æ¥ï¼‰
            import core.database.base as db_module

            db = db_module.firestore_db

            # å®‰å…¨æª¢æŸ¥ï¼ˆç†è«–ä¸Šä¸æ‡‰è©²ç™¼ç”Ÿï¼‰
            if not db:
                logger.error("âŒ Firestore æœªé€£æ¥ï¼ˆé€™ä¸æ‡‰è©²ç™¼ç”Ÿï¼Œè«‹æª¢æŸ¥æ‡‰ç”¨å•Ÿå‹•æ—¥èªŒï¼‰")
                return cls.create_error_response(
                    error="Firestoreæ•¸æ“šåº«æœªé€£æ¥ï¼Œè«‹é‡å•Ÿæ‡‰ç”¨æˆ–è¯ç¹«ç®¡ç†å“¡",
                    code="DB_NOT_CONNECTED"
                )

            logger.debug("âœ… ä½¿ç”¨ Firestore æ•¸æ“šåº«é€£æ¥")

            # è§£æåƒæ•¸ï¼ˆ_user_id ç”± coordinator æ³¨å…¥ï¼‰
            user_id = arguments.get('_user_id')
            metric_type = arguments.get('metric_type', 'all')
            days = arguments.get('days', 7)
            latest_only = arguments.get('latest_only', False)
            aggregation = arguments.get('aggregation', 'none')

            # å¦‚æœæ²’æœ‰æä¾› user_idï¼Œè¿”å›éŒ¯èª¤
            if not user_id:
                return cls.create_error_response(
                    error="éœ€è¦æä¾›ç”¨æˆ¶ ID",
                    code="USER_ID_REQUIRED"
                )

            # Firestore æŸ¥è©¢ - çµ±ä¸€ä½¿ç”¨ health_data é›†åˆ
            # iOS APP å¯«å…¥è·¯å¾‘: health_data/{doc_id} (åŒ…å« user_id å­—æ®µ)
            health_collection = db.collection('health_data')
            query = health_collection.where(
                filter=FieldFilter("user_id", "==", user_id)
            )
            logger.debug("ğŸ“Œ æŸ¥è©¢ user_id æ¢ä»¶: %s", user_id)

            # æ·»åŠ æ™‚é–“ç¯„åœéæ¿¾
            start_date = datetime.utcnow() - timedelta(days=days)
            query = query.where(
                filter=FieldFilter("timestamp", ">=", start_date)
            )
            logger.debug("ğŸ“† æŸ¥è©¢æ™‚é–“ç¯„åœ: %s ä¹‹å¾Œ", start_date.isoformat())

            # æ·»åŠ  metric_type éæ¿¾ - ä¿®æ­£å­—æ®µåç¨±
            if metric_type != 'all':
                query = query.where(
                    filter=FieldFilter("type", "==", metric_type)  # iOSå¯«å…¥æ™‚ä½¿ç”¨"type"å­—æ®µ
                )
                logger.debug("ğŸ¯ æŒ‡æ¨™éæ¿¾: %s", metric_type)
            else:
                logger.debug("ğŸ¯ æŒ‡æ¨™éæ¿¾: å…¨éƒ¨")
            
            # æ’åºå’Œé™åˆ¶
            query = query.order_by("timestamp", direction=firestore.Query.DESCENDING)
            if latest_only:
                query = query.limit(1)
                logger.debug("â± åªå–æœ€æ–°ä¸€ç­†è³‡æ–™")
            logger.debug("ğŸ“¥ å³å°‡åŸ·è¡Œ Firestore æŸ¥è©¢ (latest_only=%s)", latest_only)
            # åŸ·è¡ŒæŸ¥è©¢
            docs = query.get()
            logger.info("ğŸ“Š æŸ¥è©¢å®Œæˆï¼Œå…±å–å¾— %d ç­†åŸå§‹æ–‡ä»¶", len(docs))
            
            # æ”¶é›†æ•¸æ“š
            data = []
            for doc in docs:
                doc_data = doc.to_dict()
                data_point = {
                    "metric": doc_data["type"],  # ä¿®æ­£å­—æ®µåç¨±
                    "value": doc_data["value"],
                    "unit": doc_data["unit"],
                    "timestamp": doc_data["timestamp"].isoformat() if hasattr(doc_data["timestamp"], 'isoformat') else str(doc_data["timestamp"]),
                    "source": doc_data.get("source", "iOS HealthKit"),
                    "device_id": doc_data.get("device_id")
                }
                data.append(data_point)
            
            # æ•¸æ“šèšåˆï¼ˆå¦‚æœéœ€è¦ï¼‰
            if aggregation != 'none' and data:
                data = cls._aggregate_data(data, aggregation)
                logger.debug("ğŸ§® èšåˆæ¨¡å¼: %sï¼Œèšåˆå¾Œç­†æ•¸: %d", aggregation, len(data))
            else:
                logger.debug("ğŸ§® æœªé€²è¡Œé¡å¤–èšåˆ")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = cls._generate_summary(data, metric_type)
            logger.info("âœ… æˆåŠŸç”¢ç”Ÿæ‘˜è¦ã€‚ç­†æ•¸: %d, metric_type: %s", len(data), metric_type)
            
            # ç²å–è¨­å‚™è³‡è¨Šï¼ˆå¯é¸ï¼‰- å¾å¥åº·æ•¸æ“šä¸­æ¨æ–·
            device_info = None
            try:
                if data:
                    # å¾æœ€æ–°çš„å¥åº·æ•¸æ“šä¸­ç²å–è¨­å‚™ä¿¡æ¯
                    latest_record = data[0]  # æ•¸æ“šå·²æŒ‰æ™‚é–“é™åºæ’åˆ—
                    device_id = latest_record.get("device_id")
                    if device_id:
                        device_info = {
                            "device_id": device_id,
                            "last_sync": latest_record.get("timestamp")
                        }
            except Exception:
                pass  # è¨­å‚™è³‡è¨Šæ˜¯å¯é¸çš„
            
            # é™åˆ¶è¿”å›çµ¦å‰ç«¯çš„æ•¸æ“šé‡ï¼ˆé¿å…å‚³è¼¸éå¤šæ•¸æ“šï¼‰
            # å‰ç«¯å·¥å…·å¡ç‰‡åªé¡¯ç¤ºæœ€æ–°çš„ 20 ç­†ï¼Œä½† count é¡¯ç¤ºç¸½æ•¸
            display_limit = 20
            display_data = data[:display_limit] if len(data) > display_limit else data
            
            return cls.create_success_response(
                content=summary,
                data={
                    "raw_data": {
                        "health_data": display_data,
                        "count": len(data),
                        "total_records": len(data),
                        "displayed_records": len(display_data),
                        "query": {
                            "metric_type": metric_type,
                            "days": days,
                            "latest_only": latest_only,
                            "aggregation": aggregation
                        },
                        "device_info": device_info
                    }
                }
            )
            
        except Exception as e:
            logger.exception("âŒ æŸ¥è©¢å¥åº·æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤")
            raise ExecutionError(f"æŸ¥è©¢å¥åº·æ•¸æ“šå¤±æ•—: {str(e)}", e)
    
    @classmethod
    def _aggregate_data(cls, data: List[Dict], aggregation: str) -> List[Dict]:
        """èšåˆå¥åº·æ•¸æ“š"""
        if aggregation == 'daily':
            # æŒ‰æ—¥æœŸåˆ†çµ„ä¸¦è¨ˆç®—å¹³å‡å€¼
            from collections import defaultdict
            daily_data = defaultdict(list)
            
            for point in data:
                date = datetime.fromisoformat(point["timestamp"]).date()
                daily_data[date].append(point)
            
            aggregated = []
            for date, points in daily_data.items():
                # æŒ‰æŒ‡æ¨™é¡å‹åˆ†çµ„
                metrics = defaultdict(list)
                for p in points:
                    metrics[p["metric"]].append(p["value"])
                
                for metric, values in metrics.items():
                    if values:  # ç¢ºä¿æœ‰æ•¸æ“š
                        avg_value = sum(values) / len(values)
                        aggregated.append({
                            "metric": metric,
                            "value": round(avg_value, 2),
                            "unit": points[0]["unit"],
                            "timestamp": date.isoformat(),
                            "aggregation": "daily_average",
                            "data_points": len(values)
                        })
            
            return sorted(aggregated, key=lambda x: x["timestamp"], reverse=True)
        
        elif aggregation == 'weekly':
            # é€±å¹³å‡ï¼ˆç°¡åŒ–å¯¦ç¾ï¼‰
            from collections import defaultdict
            import calendar
            
            weekly_data = defaultdict(list)
            
            for point in data:
                date = datetime.fromisoformat(point["timestamp"]).date()
                # ç²å–é€±æ•¸
                year, week, _ = date.isocalendar()
                week_key = f"{year}-W{week:02d}"
                weekly_data[week_key].append(point)
            
            aggregated = []
            for week_key, points in weekly_data.items():
                metrics = defaultdict(list)
                for p in points:
                    metrics[p["metric"]].append(p["value"])
                
                for metric, values in metrics.items():
                    if values:
                        avg_value = sum(values) / len(values)
                        aggregated.append({
                            "metric": metric,
                            "value": round(avg_value, 2),
                            "unit": points[0]["unit"],
                            "timestamp": week_key,
                            "aggregation": "weekly_average",
                            "data_points": len(values)
                        })
            
            return sorted(aggregated, key=lambda x: x["timestamp"], reverse=True)
        
        return data
    
    @classmethod
    def _generate_summary(cls, data: List[Dict], metric_type: str) -> str:
        """ç”Ÿæˆæ•¸æ“šæ‘˜è¦"""
        if not data:
            if metric_type == 'all':
                return "æ²’æœ‰æ‰¾åˆ°ä»»ä½•å¥åº·æ•¸æ“šã€‚è«‹ç¢ºèª iOS è¨­å‚™å·²ç™»å…¥ç›¸åŒ Google å¸³è™Ÿä¸¦è‡ªå‹•åŒæ­¥æ•¸æ“šåˆ° Firestore"
            else:
                metric_names = {
                    "heart_rate": "å¿ƒç‡",
                    "step_count": "æ­¥æ•¸", 
                    "oxygen_level": "è¡€æ°§",
                    "respiratory_rate": "å‘¼å¸é »ç‡",
                    "sleep_analysis": "ç¡çœ "
                }
                name = metric_names.get(metric_type, metric_type)
                return f"æ²’æœ‰æ‰¾åˆ° {name} æ•¸æ“šã€‚è«‹ç¢ºèª iOS è¨­å‚™å·²ç™»å…¥ç›¸åŒ Google å¸³è™Ÿä¸¦è‡ªå‹•åŒæ­¥æ•¸æ“š"
        
        metric_names = {
            "heart_rate": "å¿ƒç‡",
            "step_count": "æ­¥æ•¸",
            "oxygen_level": "è¡€æ°§", 
            "respiratory_rate": "å‘¼å¸é »ç‡",
            "sleep_analysis": "ç¡çœ "
        }
        
        if metric_type == 'all':
            # çµ±è¨ˆå„é¡æ•¸æ“š
            metrics = {}
            for point in data:
                metric = point["metric"]
                if metric not in metrics:
                    metrics[metric] = []
                metrics[metric].append(point["value"])
            
            summary = "æŸ¥è©¢åˆ°ä»¥ä¸‹å¥åº·æ•¸æ“šï¼š\n"
            for metric, values in metrics.items():
                name = metric_names.get(metric, metric)
                if values:
                    avg_value = sum(values) / len(values)
                    latest_value = values[0] if values else 0
                    # ä¸é¡¯ç¤ºè¨˜éŒ„æ•¸ï¼Œé¿å…ä½¿ç”¨è€…å›°æƒ‘
                    summary += f"â€¢ {name}: æœ€æ–° {latest_value:.1f}ï¼Œå¹³å‡ {avg_value:.1f}\n"
        else:
            name = metric_names.get(metric_type, metric_type)
            if len(data) == 1:
                point = data[0]
                timestamp = datetime.fromisoformat(point['timestamp']).strftime("%m/%d %H:%M")
                summary = f"æœ€æ–°{name}æ•¸æ“šï¼š{point['value']} {point['unit']} (è¨˜éŒ„æ–¼ {timestamp})"
            else:
                values = [p["value"] for p in data]
                avg_value = sum(values) / len(values)
                latest_value = values[0] if values else 0
                # ä¸é¡¯ç¤ºè¨˜éŒ„æ•¸ï¼Œé¿å…ä½¿ç”¨è€…å›°æƒ‘ï¼ˆAI æœƒæ ¹æ“šéœ€è¦æå–é‡é»ï¼‰
                summary = f"{name}æ•¸æ“šï¼šæœ€æ–° {latest_value:.1f} {data[0]['unit']}ï¼Œå¹³å‡ {avg_value:.1f}"
        
        return summary
