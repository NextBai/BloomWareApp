"""
éŸ³é »æƒ…ç·’è¾¨è­˜æœå‹™
ä½¿ç”¨ HuBERT ä¸­æ–‡èªéŸ³æƒ…ç·’è¾¨è­˜æ¨¡å‹é€²è¡ŒèªéŸ³èªèª¿åˆ†æ

æ”¯æ´æƒ…ç·’ï¼šangry, fear, happy, neutral, sad, surprise
"""

import io
import logging
import asyncio
import tempfile
import os
from typing import Dict, Any, Optional, Tuple
import numpy as np

from core.logging import get_logger

logger = get_logger("services.audio_emotion")

# å»¶é²å°å…¥ï¼ˆé¿å…å•Ÿå‹•æ™‚è¼‰å…¥æ¨¡å‹ï¼‰
_emotion_module = None


def _load_emotion_module():
    """å»¶é²è¼‰å…¥æƒ…ç·’è¾¨è­˜æ¨¡çµ„"""
    global _emotion_module
    if _emotion_module is None:
        try:
            from models.emotion_recognition import emotion
            _emotion_module = emotion
            logger.info("âœ… éŸ³é »æƒ…ç·’è¾¨è­˜æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ éŸ³é »æƒ…ç·’è¾¨è­˜æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
            _emotion_module = None
    return _emotion_module


class AudioEmotionService:
    """éŸ³é »æƒ…ç·’è¾¨è­˜æœå‹™"""

    # æƒ…ç·’æ¨™ç±¤æ˜ å°„ï¼ˆçµ±ä¸€æ ¼å¼ï¼‰
    EMOTION_MAP = {
        "ç”Ÿæ°£(angry)": "angry",
        "ææ‡¼(fear)": "fear",
        "é–‹å¿ƒ(happy)": "happy",
        "ä¸­æ€§(neutral)": "neutral",
        "æ‚²å‚·(sad)": "sad",
        "é©šè¨(surprise)": "surprise"
    }

    def __init__(self):
        self._initialized = False

    async def predict_from_bytes(
        self,
        audio_bytes: bytes,
        sample_rate: int = 16000
    ) -> Dict[str, Any]:
        """
        å¾éŸ³é » bytes é æ¸¬æƒ…ç·’

        Args:
            audio_bytes: PCM16 éŸ³é »æ•¸æ“š
            sample_rate: æ¡æ¨£ç‡ï¼ˆé è¨­ 16000Hzï¼‰

        Returns:
            {
                "success": bool,
                "emotion": str,  # æƒ…ç·’æ¨™ç±¤ï¼ˆangry, fear, happy, neutral, sad, surpriseï¼‰
                "confidence": float,  # ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
                "all_emotions": dict,  # æ‰€æœ‰æƒ…ç·’çš„ç½®ä¿¡åº¦
                "source": "audio",  # æƒ…ç·’ä¾†æº
                "error": str (optional)
            }
        """
        try:
            # å»¶é²è¼‰å…¥æ¨¡çµ„
            emotion_module = _load_emotion_module()
            if emotion_module is None:
                return {
                    "success": False,
                    "emotion": "neutral",
                    "confidence": 0.0,
                    "error": "æƒ…ç·’è¾¨è­˜æ¨¡çµ„æœªè¼‰å…¥"
                }

            # æª¢æŸ¥éŸ³é »é•·åº¦
            if len(audio_bytes) < sample_rate * 2:  # è‡³å°‘ 1 ç§’
                logger.warning(f"âš ï¸ éŸ³é »éçŸ­: {len(audio_bytes)} bytes")
                return {
                    "success": False,
                    "emotion": "neutral",
                    "confidence": 0.0,
                    "error": "éŸ³é »éçŸ­"
                }

            logger.info(f"ğŸ¤ é–‹å§‹éŸ³é »æƒ…ç·’è¾¨è­˜ï¼ŒéŸ³é »å¤§å°: {len(audio_bytes)} bytes")

            # ä½¿ç”¨è‡¨æ™‚æª”æ¡ˆï¼ˆemotion.predict() éœ€è¦æª”æ¡ˆè·¯å¾‘ï¼‰
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_path = temp_file.name

                # å¯«å…¥ WAV æª”æ¡ˆ
                import wave
                with wave.open(temp_path, 'wb') as wf:
                    wf.setnchannels(1)
                    wf.setsampwidth(2)  # 16-bit PCM
                    wf.setframerate(sample_rate)
                    wf.writeframes(audio_bytes)

            try:
                # åœ¨åŸ·è¡Œç·’æ± ä¸­åŸ·è¡Œï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç’°ï¼‰
                loop = asyncio.get_event_loop()
                pred_id, confidence, all_emotions = await loop.run_in_executor(
                    None,
                    emotion_module.predict,
                    temp_path
                )

                # æ˜ å°„æƒ…ç·’æ¨™ç±¤
                raw_emotion = emotion_module.id2class(pred_id)
                emotion = self.EMOTION_MAP.get(raw_emotion, "neutral")

                # è½‰æ›æ‰€æœ‰æƒ…ç·’ç½®ä¿¡åº¦
                normalized_emotions = {}
                for raw_label, score_str in all_emotions.items():
                    normalized_label = self.EMOTION_MAP.get(raw_label, raw_label)
                    normalized_emotions[normalized_label] = float(score_str)

                logger.info(f"âœ… éŸ³é »æƒ…ç·’è¾¨è­˜å®Œæˆ: {emotion} (ç½®ä¿¡åº¦: {confidence:.4f})")

                return {
                    "success": True,
                    "emotion": emotion,
                    "confidence": float(confidence),
                    "all_emotions": normalized_emotions,
                    "source": "audio"
                }

            finally:
                # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                try:
                    os.unlink(temp_path)
                except Exception:
                    pass

        except Exception as e:
            logger.exception(f"âŒ éŸ³é »æƒ…ç·’è¾¨è­˜å¤±æ•—: {e}")
            return {
                "success": False,
                "emotion": "neutral",
                "confidence": 0.0,
                "error": str(e)
            }


# å…¨åŸŸå–®ä¾‹
audio_emotion_service = AudioEmotionService()


async def predict_emotion_from_audio(
    audio_bytes: bytes,
    sample_rate: int = 16000
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå¾éŸ³é »é æ¸¬æƒ…ç·’

    Args:
        audio_bytes: PCM16 éŸ³é »æ•¸æ“š
        sample_rate: æ¡æ¨£ç‡

    Returns:
        æƒ…ç·’è¾¨è­˜çµæœ
    """
    return await audio_emotion_service.predict_from_bytes(audio_bytes, sample_rate)
