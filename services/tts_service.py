"""
OpenAI TTS æœå‹™ï¼ˆ2025 æœ€ä½³å¯¦è¸ç‰ˆï¼‰
ä½¿ç”¨ AsyncOpenAI + Streaming é€²è¡Œä½å»¶é²æ–‡å­—è½‰èªéŸ³

ç‰¹è‰²ï¼š
- ç•°æ­¥ APIï¼ˆAsyncOpenAIï¼‰
- ä¸²æµæ’­æ”¾ï¼ˆé‚Šç”Ÿæˆé‚Šæ’­æ”¾ï¼Œé™ä½ TTFBï¼‰
- æ”¯æ´æƒ…ç·’æŒ‡ä»¤ï¼ˆgpt-4o-mini-ttsï¼‰
- å¤šèªè¨€æ”¯æ´ï¼ˆè‡ªå‹•æª¢æ¸¬ï¼šä¸­æ–‡ã€è‹±æ–‡ã€å°å°¼æ–‡ã€æ—¥æ–‡ã€è¶Šå—æ–‡ï¼‰
"""

import os
import logging
import asyncio
from typing import Optional, Dict, Any, Literal, AsyncIterator
from openai import AsyncOpenAI
from openai.helpers import LocalAudioPlayer
from dotenv import load_dotenv

# çµ±ä¸€æ—¥èªŒé…ç½®
from core.logging import get_logger
logger = get_logger("services.tts")

# çµ±ä¸€é…ç½®ç®¡ç†
from core.config import settings

load_dotenv()

# æ”¯æ´çš„ TTS è²éŸ³ï¼ˆ2025 æ–°å¢ï¼šcoral, sage, verseï¼‰
VoiceType = Literal["coral", "sage", "verse", "alloy", "echo", "fable", "onyx", "nova", "shimmer"]

# æ”¯æ´çš„éŸ³é »æ ¼å¼
AudioFormat = Literal["mp3", "opus", "aac", "flac", "wav", "pcm"]

# æƒ…ç·’æŒ‡ä»¤é è¨­æ¨¡æ¿
EMOTION_INSTRUCTIONS = {
    "neutral": "ç”¨å¹³ç©©ã€è‡ªç„¶çš„èªæ°£èªªè©±",
    "happy": "ç”¨é–‹å¿ƒã€æ„‰æ‚…çš„èªæ°£èªªè©±",
    "sad": "ç”¨æº«æŸ”ã€å®‰æ…°çš„èªæ°£èªªè©±",
    "angry": "ç”¨å†·éœã€ç†æ€§çš„èªæ°£èªªè©±",
    "fear": "ç”¨æº«æš–ã€é¼“å‹µçš„èªæ°£èªªè©±",
    "surprise": "ç”¨è¼•å¿«ã€æ´»æ½‘çš„èªæ°£èªªè©±"
}

# é—œæ‡·æ¨¡å¼ç‰¹æ®ŠæŒ‡ä»¤
CARE_MODE_INSTRUCTION = "ç”¨æº«æŸ”ã€é—œæ‡·ã€é™ªä¼´çš„èªæ°£èªªè©±ï¼Œè®“å°æ–¹æ„Ÿå—åˆ°è¢«ç†è§£å’Œæ”¯æŒ"


def get_emotion_instruction(emotion: Optional[str], care_mode: bool = False) -> str:
    """
    æ ¹æ“šæƒ…ç·’é¸æ“‡å°æ‡‰çš„ TTS instruction

    Args:
        emotion: æƒ…ç·’æ¨™ç±¤ï¼ˆneutral, happy, sad, angry, fear, surpriseï¼‰
        care_mode: æ˜¯å¦ç‚ºé—œæ‡·æ¨¡å¼

    Returns:
        TTS instruction å­—ä¸²
    """
    # é—œæ‡·æ¨¡å¼å„ªå…ˆ
    if care_mode:
        return CARE_MODE_INSTRUCTION
    
    # æ ¹æ“šæƒ…ç·’é¸æ“‡
    if emotion and emotion in EMOTION_INSTRUCTIONS:
        return EMOTION_INSTRUCTIONS[emotion]
    
    # é è¨­ä¸­æ€§èªæ°£
    return EMOTION_INSTRUCTIONS["neutral"]


class TTSService:
    """OpenAI Text-to-Speech æœå‹™ï¼ˆç•°æ­¥ç‰ˆï¼‰"""

    def __init__(self):
        self._client: Optional[AsyncOpenAI] = None
        self._initialized = False

    @property
    def client(self) -> Optional[AsyncOpenAI]:
        """å»¶é²åˆå§‹åŒ– AsyncOpenAI å®¢æˆ¶ç«¯"""
        if not self._initialized:
            api_key = settings.OPENAI_API_KEY
            if api_key:
                self._client = AsyncOpenAI(
                    api_key=api_key,
                    timeout=float(settings.OPENAI_TIMEOUT),
                    max_retries=3
                )
                logger.info("âœ… TTS æœå‹™åˆå§‹åŒ–æˆåŠŸï¼ˆAsyncOpenAIï¼‰")
            else:
                logger.error("âŒ TTS æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼šOPENAI_API_KEY æœªè¨­ç½®")
            self._initialized = True
        return self._client

    async def synthesize(
        self,
        text: str,
        voice: VoiceType = "coral",
        model: str = "gpt-4o-mini-tts",
        speed: float = 1.0,
        instruction: Optional[str] = None,
        emotion: Optional[str] = None,
        care_mode: bool = False,
        response_format: AudioFormat = "mp3"
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ OpenAI TTS API å°‡æ–‡å­—è½‰èªéŸ³ï¼ˆéä¸²æµç‰ˆï¼‰

        Args:
            text: è¦è½‰æ›çš„æ–‡å­—
            voice: è²éŸ³é¡å‹ï¼ˆcoral, sage, verse, alloy, echo, fable, onyx, nova, shimmerï¼‰
            model: TTS æ¨¡å‹ï¼ˆgpt-4o-mini-tts æˆ– tts-1-hdï¼‰
            speed: èªé€Ÿï¼ˆ0.25 åˆ° 4.0ï¼‰
            instruction: èªéŸ³æŒ‡ä»¤ï¼ˆæ‰‹å‹•æŒ‡å®šï¼Œå„ªå…ˆç´šæœ€é«˜ï¼‰
            emotion: æƒ…ç·’æ¨™ç±¤ï¼ˆè‡ªå‹•é¸æ“‡ instructionï¼‰
            care_mode: æ˜¯å¦ç‚ºé—œæ‡·æ¨¡å¼ï¼ˆä½¿ç”¨ç‰¹æ®Šèªæ°£ï¼‰
            response_format: éŸ³é »æ ¼å¼ï¼ˆmp3, opus, aac, flac, wav, pcmï¼‰

        Returns:
            {
                "success": bool,
                "audio_data": bytes,
                "voice": str,
                "format": str,
                "error": str (optional)
            }
        """
        if not self.client:
            return {
                "success": False,
                "audio_data": None,
                "error": "OpenAI client æœªåˆå§‹åŒ–"
            }

        try:
            logger.info(f"ğŸ”Š é–‹å§‹ TTS åˆæˆï¼Œæ–‡å­—é•·åº¦: {len(text)}, è²éŸ³: {voice}")

            # èª¿ç”¨ OpenAI TTS APIï¼ˆ2025 æœ€ä½³å¯¦è¸ï¼šæ”¯æ´æƒ…ç·’æŒ‡ä»¤ï¼‰
            params = {
                "model": model,
                "voice": voice,
                "input": text,
                "speed": speed,
                "response_format": response_format
            }

            # é¸æ“‡ instructionï¼ˆå„ªå…ˆç´šï¼šæ‰‹å‹• > æƒ…ç·’è‡ªå‹•é¸æ“‡ï¼‰
            final_instruction = instruction or get_emotion_instruction(emotion, care_mode)
            
            # å¦‚æœæä¾›æƒ…ç·’æŒ‡ä»¤ï¼ˆgpt-4o-mini-tts æ”¯æ´ï¼‰
            if final_instruction and model == "gpt-4o-mini-tts":
                params["instructions"] = final_instruction
                logger.info(f"ğŸ­ TTS èªæ°£æŒ‡ä»¤: {final_instruction}")

            response = await self.client.audio.speech.create(**params)

            # ç²å–éŸ³é »æ•¸æ“š
            audio_data = response.content

            logger.info(f"âœ… TTS åˆæˆæˆåŠŸï¼ŒéŸ³é »å¤§å°: {len(audio_data)} bytes")

            return {
                "success": True,
                "audio_data": audio_data,
                "voice": voice,
                "format": response_format
            }

        except Exception as e:
            logger.exception(f"âŒ TTS åˆæˆå¤±æ•—: {e}")
            return {
                "success": False,
                "audio_data": None,
                "error": str(e)
            }

    async def synthesize_stream(
        self,
        text: str,
        voice: VoiceType = "coral",
        model: str = "gpt-4o-mini-tts",
        speed: float = 1.0,
        instruction: Optional[str] = None,
        emotion: Optional[str] = None,
        care_mode: bool = False,
        response_format: AudioFormat = "pcm"
    ) -> AsyncIterator[bytes]:
        """
        ä½¿ç”¨ OpenAI TTS API ä¸²æµç”ŸæˆèªéŸ³ï¼ˆé‚Šç”Ÿæˆé‚Šæ’­æ”¾ï¼Œä½å»¶é²ï¼‰

        Args:
            text: è¦è½‰æ›çš„æ–‡å­—
            voice: è²éŸ³é¡å‹
            model: TTS æ¨¡å‹
            speed: èªé€Ÿ
            instruction: èªéŸ³æŒ‡ä»¤ï¼ˆæ‰‹å‹•æŒ‡å®šï¼Œå„ªå…ˆç´šæœ€é«˜ï¼‰
            emotion: æƒ…ç·’æ¨™ç±¤ï¼ˆè‡ªå‹•é¸æ“‡ instructionï¼‰
            care_mode: æ˜¯å¦ç‚ºé—œæ‡·æ¨¡å¼
            response_format: éŸ³é »æ ¼å¼ï¼ˆå»ºè­°ç”¨ pcm ä»¥ç²å¾—æœ€ä½å»¶é²ï¼‰

        Yields:
            bytes: éŸ³é »æ•¸æ“šå¡Š
        """
        if not self.client:
            logger.error("âŒ OpenAI client æœªåˆå§‹åŒ–")
            return

        try:
            logger.info(f"ğŸ”Š é–‹å§‹ TTS ä¸²æµåˆæˆï¼Œæ–‡å­—é•·åº¦: {len(text)}, è²éŸ³: {voice}")

            # èª¿ç”¨ OpenAI TTS APIï¼ˆä¸²æµæ¨¡å¼ï¼‰
            params = {
                "model": model,
                "voice": voice,
                "input": text,
                "speed": speed,
                "response_format": response_format
            }

            # é¸æ“‡ instructionï¼ˆå„ªå…ˆç´šï¼šæ‰‹å‹• > æƒ…ç·’è‡ªå‹•é¸æ“‡ï¼‰
            final_instruction = instruction or get_emotion_instruction(emotion, care_mode)
            
            if final_instruction and model == "gpt-4o-mini-tts":
                params["instructions"] = final_instruction
                logger.info(f"ğŸ­ TTS ä¸²æµèªæ°£æŒ‡ä»¤: {final_instruction}")

            async with self.client.audio.speech.with_streaming_response.create(**params) as response:
                logger.info("âœ… TTS ä¸²æµå·²å•Ÿå‹•")
                
                # é€å¡Šç”¢å‡ºéŸ³é »æ•¸æ“š
                async for chunk in response.iter_bytes(chunk_size=4096):
                    if chunk:
                        yield chunk

                logger.info("âœ… TTS ä¸²æµå®Œæˆ")

        except Exception as e:
            logger.exception(f"âŒ TTS ä¸²æµå¤±æ•—: {e}")

    async def play_locally(
        self,
        text: str,
        voice: VoiceType = "coral",
        model: str = "gpt-4o-mini-tts",
        speed: float = 1.0,
        instruction: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LocalAudioPlayer ç›´æ¥æ’­æ”¾èªéŸ³ï¼ˆæœ¬åœ°æ¸¬è©¦ç”¨ï¼‰

        Args:
            text: è¦è½‰æ›çš„æ–‡å­—
            voice: è²éŸ³é¡å‹
            model: TTS æ¨¡å‹
            speed: èªé€Ÿ
            instruction: èªéŸ³æŒ‡ä»¤

        Returns:
            {
                "success": bool,
                "error": str (optional)
            }
        """
        if not self.client:
            return {
                "success": False,
                "error": "OpenAI client æœªåˆå§‹åŒ–"
            }

        try:
            logger.info(f"ğŸ”Š é–‹å§‹æœ¬åœ°æ’­æ”¾ï¼Œæ–‡å­—é•·åº¦: {len(text)}, è²éŸ³: {voice}")

            params = {
                "model": model,
                "voice": voice,
                "input": text,
                "speed": speed,
                "response_format": "pcm"
            }

            if instruction and model == "gpt-4o-mini-tts":
                params["instructions"] = instruction

            async with self.client.audio.speech.with_streaming_response.create(**params) as response:
                await LocalAudioPlayer().play(response)

            logger.info("âœ… æœ¬åœ°æ’­æ”¾å®Œæˆ")

            return {
                "success": True
            }

        except Exception as e:
            logger.exception(f"âŒ æœ¬åœ°æ’­æ”¾å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }


# å…¨åŸŸå–®ä¾‹
tts_service = TTSService()


async def text_to_speech(
    text: str,
    voice: VoiceType = "coral",
    speed: float = 1.0,
    instruction: Optional[str] = None
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå°‡æ–‡å­—è½‰ç‚ºèªéŸ³ï¼ˆéä¸²æµï¼‰

    Args:
        text: è¦è½‰æ›çš„æ–‡å­—
        voice: è²éŸ³é¡å‹ï¼ˆcoral, sage, verse, alloy, echo, fable, onyx, nova, shimmerï¼‰
        speed: èªé€Ÿï¼ˆ0.25 åˆ° 4.0ï¼‰
        instruction: èªéŸ³æŒ‡ä»¤ï¼ˆå¦‚ã€Œç”¨æº«æŸ”ã€å®‰æ…°çš„èªæ°£èªªè©±ã€ï¼‰

    Returns:
        {
            "success": bool,
            "audio_data": bytes,
            "voice": str,
            "format": str,
            "error": str (optional)
        }
    """
    return await tts_service.synthesize(text, voice, speed=speed, instruction=instruction)


async def text_to_speech_stream(
    text: str,
    voice: VoiceType = "coral",
    speed: float = 1.0,
    instruction: Optional[str] = None
) -> AsyncIterator[bytes]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå°‡æ–‡å­—è½‰ç‚ºèªéŸ³ï¼ˆä¸²æµæ¨¡å¼ï¼Œä½å»¶é²ï¼‰

    Args:
        text: è¦è½‰æ›çš„æ–‡å­—
        voice: è²éŸ³é¡å‹
        speed: èªé€Ÿ
        instruction: èªéŸ³æŒ‡ä»¤

    Yields:
        bytes: éŸ³é »æ•¸æ“šå¡Š
    """
    async for chunk in tts_service.synthesize_stream(text, voice, speed=speed, instruction=instruction):
        yield chunk


async def test_tts_playback(
    text: str = "ä»Šå¤©æ˜¯ç¾å¥½çš„ä¸€å¤©ï¼",
    voice: VoiceType = "coral",
    instruction: Optional[str] = "ç”¨é–‹å¿ƒã€æ„‰æ‚…çš„èªæ°£èªªè©±"
) -> None:
    """
    å¿«é€Ÿæ¸¬è©¦ TTS æ’­æ”¾ï¼ˆä½¿ç”¨ LocalAudioPlayerï¼‰

    Args:
        text: è¦æ’­æ”¾çš„æ–‡å­—
        voice: è²éŸ³é¡å‹
        instruction: èªéŸ³æŒ‡ä»¤
    """
    result = await tts_service.play_locally(text, voice=voice, instruction=instruction)
    if result["success"]:
        logger.debug(f"âœ… æ’­æ”¾æˆåŠŸï¼š{text}")
    else:
        logger.debug(f"âŒ æ’­æ”¾å¤±æ•—ï¼š{result.get('error')}")


if __name__ == "__main__":
    # æ¸¬è©¦ç¯„ä¾‹ï¼šæ’­æ”¾ä¸­æ–‡èªéŸ³
    asyncio.run(test_tts_playback(
        text="ä½ å¥½ï¼æˆ‘æ˜¯ BloomWare æ™ºèƒ½åŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆç‚ºä½ æœå‹™ï¼",
        voice="coral",
        instruction="ç”¨æº«æš–ã€å‹å–„çš„èªæ°£èªªè©±"
    ))
