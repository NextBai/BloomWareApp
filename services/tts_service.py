"""
OpenAI TTS æœå‹™
ä½¿ç”¨ OpenAI Text-to-Speech API é€²è¡Œæ–‡å­—è½‰èªéŸ³
"""

import os
import logging
from typing import Optional, Dict, Any, Literal
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger("services.tts")

# OpenAI é…ç½®
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("âš ï¸ OPENAI_API_KEY æœªè¨­ç½®")

client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# æ”¯æ´çš„ TTS è²éŸ³
VoiceType = Literal["alloy", "echo", "fable", "onyx", "nova", "shimmer"]


class TTSService:
    """OpenAI Text-to-Speech æœå‹™"""

    def __init__(self):
        self.client = client
        if not self.client:
            logger.error("âŒ OpenAI client åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ OPENAI_API_KEY")

    async def synthesize(
        self,
        text: str,
        voice: VoiceType = "nova",
        model: str = "gpt-4o-mini-tts",
        speed: float = 1.0,
        instruction: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ OpenAI TTS API å°‡æ–‡å­—è½‰èªéŸ³ï¼ˆ2025 æœ€ä½³å¯¦è¸ï¼šgpt-4o-mini-ttsï¼‰

        Args:
            text: è¦è½‰æ›çš„æ–‡å­—
            voice: è²éŸ³é¡å‹ï¼ˆalloy, echo, fable, onyx, nova, shimmerï¼‰
            model: TTS æ¨¡å‹ï¼ˆgpt-4o-mini-tts æˆ– tts-1-hdï¼‰
            speed: èªé€Ÿï¼ˆ0.25 åˆ° 4.0ï¼‰
            instruction: èªéŸ³æŒ‡ä»¤ï¼ˆå¦‚ã€Œç”¨æº«æŸ”ã€å®‰æ…°çš„èªæ°£èªªè©±ã€ï¼‰

        Returns:
            {
                "success": bool,
                "audio_data": bytes,  # MP3 éŸ³é »æ•¸æ“š
                "voice": str,
                "error": str  # éŒ¯èª¤è¨Šæ¯ï¼ˆå¦‚æœå¤±æ•—ï¼‰
            }
        """
        if not self.client:
            return {
                "success": False,
                "audio_data": None,
                "error": "OpenAI client æœªåˆå§‹åŒ–"
            }

        try:
            logger.info(f"ğŸ”Š é–‹å§‹ TTS åˆæˆï¼Œæ–‡å­—é•·åº¦: {len(text)}, è²éŸ³: {voice}")

            # èª¿ç”¨ OpenAI TTS APIï¼ˆ2025 æœ€ä½³å¯¦è¸ï¼šæ”¯æ´æƒ…ç·’æŒ‡ä»¤ï¼‰
            params = {
                "model": model,
                "voice": voice,
                "input": text,
                "speed": speed
            }

            # å¦‚æœæä¾›æƒ…ç·’æŒ‡ä»¤ï¼ˆgpt-4o-mini-tts æ”¯æ´ï¼‰
            if instruction and model == "gpt-4o-mini-tts":
                params["instruction"] = instruction

            response = self.client.audio.speech.create(**params)

            # ç²å–éŸ³é »æ•¸æ“šï¼ˆMP3 æ ¼å¼ï¼‰
            audio_data = response.content

            logger.info(f"âœ… TTS åˆæˆæˆåŠŸï¼ŒéŸ³é »å¤§å°: {len(audio_data)} bytes")

            return {
                "success": True,
                "audio_data": audio_data,
                "voice": voice
            }

        except Exception as e:
            logger.exception(f"âŒ TTS åˆæˆå¤±æ•—: {e}")
            return {
                "success": False,
                "audio_data": None,
                "error": str(e)
            }


# å…¨åŸŸå–®ä¾‹
tts_service = TTSService()


async def text_to_speech(
    text: str,
    voice: VoiceType = "nova",
    speed: float = 1.0
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå°‡æ–‡å­—è½‰ç‚ºèªéŸ³

    Args:
        text: è¦è½‰æ›çš„æ–‡å­—
        voice: è²éŸ³é¡å‹ï¼ˆalloy, echo, fable, onyx, nova, shimmerï¼‰
        speed: èªé€Ÿï¼ˆ0.25 åˆ° 4.0ï¼‰

    Returns:
        {
            "success": bool,
            "audio_data": bytes,
            "voice": str,
            "error": str (optional)
        }
    """
    return await tts_service.synthesize(text, voice, speed=speed)
